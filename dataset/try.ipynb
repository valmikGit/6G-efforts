{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242484fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import h5py\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from time import time\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "\n",
    "# ============ Visualization Setup ============\n",
    "plt.ioff()\n",
    "plt.rcParams['figure.constrained_layout.use'] = True\n",
    "os.makedirs(\"progress_plots\", exist_ok=True)\n",
    "os.makedirs(\"architecture_plots\", exist_ok=True)\n",
    "os.makedirs(\"channel_estimates\", exist_ok=True)\n",
    "\n",
    "def plot_losses(epochs, train_losses, val_losses, test_losses=None):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6), constrained_layout=True)\n",
    "        \n",
    "        # Training and Validation Loss\n",
    "        ax1.plot(epochs, train_losses, label='Train Loss')\n",
    "        ax1.plot(epochs, val_losses, label='Val Loss')\n",
    "        ax1.set_title('Training & Validation Loss', fontsize=12)\n",
    "        ax1.set_xlabel('Epochs', fontsize=10)\n",
    "        ax1.set_ylabel('MSE Loss', fontsize=10)\n",
    "        if all(y > 0 for y in train_losses + val_losses):\n",
    "            ax1.set_yscale('log')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True)\n",
    "\n",
    "        # Test Loss if available\n",
    "        if test_losses:\n",
    "            ax2.plot(test_losses['epochs'], test_losses['values'], 'r-')\n",
    "            ax2.set_title('Test Loss Progression', fontsize=12)\n",
    "            ax2.set_xlabel('Epochs', fontsize=10)\n",
    "            ax2.set_ylabel('MSE Loss', fontsize=10)\n",
    "            if all(y > 0 for y in test_losses['values']):\n",
    "                ax2.set_yscale('log')\n",
    "            ax2.grid(True)\n",
    "\n",
    "        plt.savefig(f\"progress_plots/losses_{int(time())}.png\")\n",
    "        plt.close()\n",
    "\n",
    "def plot_architecture(alphas, epoch):\n",
    "    \"\"\"Plot the evolution of alpha parameters\"\"\"\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        fig = plt.figure(figsize=(18, 16), constrained_layout=True)\n",
    "        keys = sorted(alphas.keys())\n",
    "        \n",
    "        for i, (edge, alpha) in enumerate(alphas.items()):\n",
    "            ax = fig.add_subplot(4, 2, i+1)  # 4 rows, 2 columns\n",
    "            ax.bar(range(len(alpha)), alpha, width=0.6)\n",
    "            ax.set_title(f'Edge {edge} Alpha Values', fontsize=10)\n",
    "            ax.set_xlabel('Operation', fontsize=8)\n",
    "            ax.set_ylabel('Weight', fontsize=8)\n",
    "            ax.set_xticks(range(len(alpha)))\n",
    "            ax.set_xticklabels(list(OPS.keys()), rotation=60, ha='right', fontsize=7)\n",
    "            ax.tick_params(axis='y', labelsize=7)\n",
    "            \n",
    "        plt.savefig(f\"architecture_plots/alpha_epoch_{epoch}.png\")\n",
    "        plt.close()\n",
    "\n",
    "def plot_channel_estimates(model, test_loader, epoch, num_examples=3):\n",
    "    \"\"\"Plot example channel estimates\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (real_in, imag_in, real_tar, imag_tar) in enumerate(test_loader):\n",
    "            if i >= num_examples:\n",
    "                break\n",
    "            inputs = torch.cat([real_in.unsqueeze(1), imag_in.unsqueeze(1)], dim=1).to(device)\n",
    "            preds = model(inputs)\n",
    "            rpred, ipred = preds.chunk(2, dim=1)\n",
    "            \n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5), constrained_layout=True)\n",
    "            \n",
    "            ax1.plot(real_tar[0].numpy(), label='True Real')\n",
    "            ax1.plot(rpred[0].cpu().numpy(), label='Predicted Real')\n",
    "            ax1.set_title('Real Component', fontsize=10)\n",
    "            ax1.legend()\n",
    "            \n",
    "            ax2.plot(imag_tar[0].numpy(), label='True Imag')\n",
    "            ax2.plot(ipred[0].cpu().numpy(), label='Predicted Imag')\n",
    "            ax2.set_title('Imaginary Component', fontsize=10)\n",
    "            ax2.legend()\n",
    "            \n",
    "            plt.savefig(f\"channel_estimates/epoch_{epoch}_example_{i}.png\")\n",
    "            plt.close()\n",
    "\n",
    "def plot_learning_rates(lr_history):\n",
    "    \"\"\"Plot learning rate evolution\"\"\"\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5), constrained_layout=True)\n",
    "        \n",
    "        ax1.plot(lr_history['w_lr'], label='Weight LR')\n",
    "        ax1.set_title('Weight Learning Rate', fontsize=10)\n",
    "        ax1.set_xlabel('Epoch', fontsize=8)\n",
    "        ax1.set_ylabel('Learning Rate', fontsize=8)\n",
    "        \n",
    "        ax2.plot(lr_history['alpha_lr'], label='Alpha LR')\n",
    "        ax2.set_title('Alpha Learning Rate', fontsize=10)\n",
    "        ax2.set_xlabel('Epoch', fontsize=8)\n",
    "        ax2.set_ylabel('Learning Rate', fontsize=8)\n",
    "        \n",
    "        plt.savefig(f\"progress_plots/learning_rates_{int(time())}.png\")\n",
    "        plt.close()\n",
    "\n",
    "def plot_gradient_norms(grad_norms):\n",
    "    \"\"\"Plot gradient norms over time\"\"\"\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5), constrained_layout=True)\n",
    "        \n",
    "        for name, norms in grad_norms['weight'].items():\n",
    "            ax1.plot(norms, label=name)\n",
    "        ax1.set_title('Weight Gradient Norms', fontsize=10)\n",
    "        ax1.set_xlabel('Epoch', fontsize=8)\n",
    "        ax1.set_ylabel('Gradient Norm', fontsize=8)\n",
    "        if any(n > 0 for n in norms):\n",
    "            ax1.set_yscale('log')\n",
    "        ax1.legend(fontsize=7)\n",
    "        \n",
    "        for name, norms in grad_norms['alpha'].items():\n",
    "            ax2.plot(norms, label=name)\n",
    "        ax2.set_title('Alpha Gradient Norms', fontsize=10)\n",
    "        ax2.set_xlabel('Epoch', fontsize=8)\n",
    "        ax2.set_ylabel('Gradient Norm', fontsize=8)\n",
    "        if any(n > 0 for n in norms):\n",
    "            ax2.set_yscale('log')\n",
    "        ax2.legend(fontsize=7)\n",
    "        \n",
    "        plt.savefig(f\"progress_plots/gradient_norms_{int(time())}.png\")\n",
    "        plt.close()\n",
    "\n",
    "# ============ GPU Setup ============\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ============ Load .mat Files with Fallback ============\n",
    "def load_mat_file(file_path, var_name):\n",
    "    try:\n",
    "        with h5py.File(file_path, 'r') as f:\n",
    "            data = f[var_name][:]\n",
    "        print(f\"Loaded {file_path} using h5py.\")\n",
    "    except OSError:\n",
    "        print(f\"Failed to load {file_path} with h5py. Trying scipy.io.loadmat...\")\n",
    "        data = loadmat(file_path)[var_name]\n",
    "        print(f\"Loaded {file_path} using scipy.io.loadmat.\")\n",
    "    return data\n",
    "\n",
    "# ============ Load Data ============\n",
    "def load_data():\n",
    "    data_y = load_mat_file('yDL_10dB_40k_150pilots_ipjp.mat', 'yDL')\n",
    "    data_psi = load_mat_file('PsiDL_10dB_40k_150pilots_ipjp.mat', 'PsiDL')\n",
    "    data_h = load_mat_file('hDL_10dB_40k_150pilots_ipjp.mat', 'hDL')\n",
    "    data_sigma2 = load_mat_file('sigma2DL_10dB_40k_150pilots_ipjp.mat', 'sigma2DL')\n",
    "\n",
    "    y_complex_np = data_y[..., 0] + 1j * data_y[..., 1]\n",
    "    h_complex_np = data_h[..., 0] + 1j * data_h[..., 1]\n",
    "    \n",
    "    psi_real_np = data_psi[0].transpose(2, 0, 1)\n",
    "    psi_imag_np = data_psi[1].transpose(2, 0, 1)\n",
    "    sigma2_np = data_sigma2.squeeze()\n",
    "    \n",
    "    # Verify shapes\n",
    "    print(f\"y_complex_np shape: {y_complex_np.shape}\")\n",
    "    print(f\"psi_real_np shape: {psi_real_np.shape}\")\n",
    "    print(f\"psi_imag_np shape: {psi_imag_np.shape}\")\n",
    "    print(f\"h_complex_np shape: {h_complex_np.shape}\")\n",
    "    print(f\"sigma2_np shape: {sigma2_np.shape}\")\n",
    "    \n",
    "    return y_complex_np, psi_real_np, psi_imag_np, h_complex_np, sigma2_np\n",
    "\n",
    "y_complex_np, psi_real_np, psi_imag_np, h_complex_np, sigma2_np = load_data()\n",
    "\n",
    "# ============ SBL Update Function ============\n",
    "def sbl_update_batch(Psi, y, Gamma_init, sigma2):\n",
    "    # ... (Same as before) ...\n",
    "\n",
    "# ============ Compute SBL Estimate ============\n",
    "num_samples = 40000\n",
    "batch_size = 1000\n",
    "h_SBL_complex = torch.empty((num_samples, 512), dtype=torch.cfloat, device=device)\n",
    "\n",
    "for start in range(0, num_samples, batch_size):\n",
    "    # ... (Same as before) ...\n",
    "\n",
    "print(\"SBL estimation completed!\")\n",
    "\n",
    "# Prepare tensors for dataset\n",
    "h_SBL_real, h_SBL_imag = h_SBL_complex.real, h_SBL_complex.imag\n",
    "h_real = torch.tensor(h_complex_np.real, dtype=torch.float32)\n",
    "h_imag = torch.tensor(h_complex_np.imag, dtype=torch.float32)\n",
    "\n",
    "# Move to CPU if needed\n",
    "if device.type == 'cuda':\n",
    "    h_SBL_real = h_SBL_real.cpu()\n",
    "    h_SBL_imag = h_SBL_imag.cpu()\n",
    "    h_real = h_real.cpu()\n",
    "    h_imag = h_imag.cpu()\n",
    "\n",
    "# ============ CRITICAL CHANGE: Data Normalization ============\n",
    "# Calculate mean and std from training data only\n",
    "train_samples = 32000\n",
    "sbl_real_mean = h_SBL_real[:train_samples].mean()\n",
    "sbl_real_std = h_SBL_real[:train_samples].std()\n",
    "sbl_imag_mean = h_SBL_imag[:train_samples].mean()\n",
    "sbl_imag_std = h_SBL_imag[:train_samples].std()\n",
    "\n",
    "h_real_mean = h_real[:train_samples].mean()\n",
    "h_real_std = h_real[:train_samples].std()\n",
    "h_imag_mean = h_imag[:train_samples].mean()\n",
    "h_imag_std = h_imag[:train_samples].std()\n",
    "\n",
    "# Normalize all data\n",
    "h_SBL_real = (h_SBL_real - sbl_real_mean) / sbl_real_std\n",
    "h_SBL_imag = (h_SBL_imag - sbl_imag_mean) / sbl_imag_std\n",
    "h_real = (h_real - h_real_mean) / h_real_std\n",
    "h_imag = (h_imag - h_imag_mean) / h_imag_std\n",
    "\n",
    "# ============ Dataset Split ============\n",
    "train_samples, val_samples, test_samples = 32000, 4000, 4000\n",
    "\n",
    "train_dataset = TensorDataset(\n",
    "    h_SBL_real[:train_samples], \n",
    "    h_SBL_imag[:train_samples],\n",
    "    h_real[:train_samples], \n",
    "    h_imag[:train_samples]\n",
    ")\n",
    "\n",
    "val_dataset = TensorDataset(\n",
    "    h_SBL_real[train_samples:train_samples+val_samples],\n",
    "    h_SBL_imag[train_samples:train_samples+val_samples],\n",
    "    h_real[train_samples:train_samples+val_samples],\n",
    "    h_imag[train_samples:train_samples+val_samples]\n",
    ")\n",
    "\n",
    "test_dataset = TensorDataset(\n",
    "    h_SBL_real[train_samples+val_samples:],\n",
    "    h_SBL_imag[train_samples+val_samples:],\n",
    "    h_real[train_samples+val_samples:],\n",
    "    h_imag[train_samples+val_samples:]\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# ============ Neural Architecture Components ============\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(2, 16, 3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(16, 32, 3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        return F.relu(self.conv2(x))\n",
    "\n",
    "# Modified OPS without skip_connection\n",
    "OPS = {\n",
    "    'zero': lambda C: nn.ZeroPad1d(0),\n",
    "    'conv_3x3': lambda C: nn.Conv1d(C, C, 3, padding=1, bias=False),\n",
    "    'sep_conv_3x3': lambda C: nn.Sequential(\n",
    "        nn.Conv1d(C, C, 3, padding=1, groups=C, bias=False),\n",
    "        nn.Conv1d(C, C, 1, bias=False),\n",
    "        nn.BatchNorm1d(C)\n",
    "    ),\n",
    "    'dil_conv_3x3': lambda C: nn.Conv1d(C, C, 3, padding=2, dilation=2, bias=False),\n",
    "}\n",
    "\n",
    "class DenoiseCell(nn.Module):\n",
    "    def __init__(self, C):\n",
    "        super().__init__()\n",
    "        self.C = C\n",
    "        self.num_edges = 8\n",
    "        self.num_ops = len(OPS)\n",
    "        self.alphas = nn.Parameter(torch.randn(self.num_edges, self.num_ops))\n",
    "        self.ops = nn.ModuleList([nn.ModuleList([op(C) for op in OPS.values()]) \n",
    "                                   for _ in range(self.num_edges)])\n",
    "        self.conv1x1 = nn.Conv1d(8*C, C, 1, bias=False)\n",
    "\n",
    "    def pad_and_concat(self, inputs):\n",
    "        max_size = max(inp.shape[2] for inp in inputs)\n",
    "        padded_inputs = [F.pad(inp, (0, max_size - inp.shape[2])) if inp.shape[2] < max_size else inp\n",
    "                         for inp in inputs]\n",
    "        return torch.cat(padded_inputs, dim=1)\n",
    "\n",
    "    def apply_ops(self, x, edge_idx):\n",
    "        weights = F.softmax(self.alphas[edge_idx], dim=-1)\n",
    "        return sum(w * op(x) for w, op in zip(weights, self.ops[edge_idx]))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        in0, in1 = inputs\n",
    "        \n",
    "        node0 = self.pad_and_concat([in0, in1])\n",
    "        node0 = F.relu(node0)\n",
    "        \n",
    "        node1 = F.relu(node0)\n",
    "        \n",
    "        node2 = self.pad_and_concat([node0, node1])\n",
    "        node2 = F.relu(node2)\n",
    "        \n",
    "        node3_inputs = self.pad_and_concat([node0, node1, node2])\n",
    "        \n",
    "        node3 = F.relu(self.conv1x1(node3_inputs))\n",
    "        return node3\n",
    "\n",
    "class DenoiseModule(nn.Module):\n",
    "    def __init__(self, C):\n",
    "        super().__init__()\n",
    "        self.cells = nn.ModuleList([DenoiseCell(C) for _ in range(10)])\n",
    "        self.state_history = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = [x, x]\n",
    "        self.state_history = []\n",
    "        for i in range(10):\n",
    "            if i == 0:\n",
    "                out = self.cells[i]([outputs[0], outputs[0]])\n",
    "            elif i == 1:\n",
    "                out = self.cells[i]([outputs[1], outputs[0]])\n",
    "            else:\n",
    "                out = self.cells[i]([outputs[-2], outputs[-1]])\n",
    "            outputs.append(out)\n",
    "            self.state_history.append({\n",
    "                'outputs': list(outputs),\n",
    "                'alpha': list(self.parameters())\n",
    "            })\n",
    "        return outputs[-1]\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Full connection layer (1x1 convolution)\n",
    "        self.fc = nn.Conv1d(32, 32, kernel_size=1)\n",
    "        \n",
    "        # First separable convolution block\n",
    "        self.sep_conv1 = nn.Sequential(\n",
    "            nn.Conv1d(32, 32, 3, padding=1, groups=32, bias=False),\n",
    "            nn.Conv1d(32, 32, 1, bias=False),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Second separable convolution block\n",
    "        self.sep_conv2 = nn.Sequential(\n",
    "            nn.Conv1d(32, 32, 3, padding=1, groups=32, bias=False),\n",
    "            nn.Conv1d(32, 16, 1, bias=False),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Final convolution layer\n",
    "        self.final_conv = nn.Conv1d(16, 2, 3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc(x))\n",
    "        x = self.sep_conv1(x)\n",
    "        x = self.sep_conv2(x)\n",
    "        return self.final_conv(x)\n",
    "\n",
    "class FullModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = FeatureExtractor()\n",
    "        self.denoiser = DenoiseModule(32)\n",
    "        self.decoder = Decoder()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.denoiser(x)\n",
    "        return self.decoder(x)\n",
    "\n",
    "# ============ Evaluation Function ============\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for real_in, imag_in, real_tar, imag_tar in loader:\n",
    "            inputs = torch.cat([real_in.unsqueeze(1), imag_in.unsqueeze(1)], dim=1).to(device)\n",
    "            targets = torch.cat([real_tar.unsqueeze(1), imag_tar.unsqueeze(1)], dim=1).to(device)\n",
    "            \n",
    "            preds = model(inputs)\n",
    "            loss = criterion(preds, targets)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# ============ Truncated RAD Implementation ============\n",
    "def compute_truncated_grad(model, val_batch, criterion, truncation_steps=3):\n",
    "    real_in, imag_in, real_tar, imag_tar = val_batch\n",
    "    real_in = real_in.unsqueeze(1).to(device)\n",
    "    imag_in = imag_in.unsqueeze(1).to(device)\n",
    "    inputs = torch.cat([real_in, imag_in], dim=1)\n",
    "    \n",
    "    real_tar = real_tar.unsqueeze(1).to(device)\n",
    "    imag_tar = imag_tar.unsqueeze(1).to(device)\n",
    "    targets = torch.cat([real_tar, imag_tar], dim=1)\n",
    "\n",
    "    # Forward pass through unrolled steps\n",
    "    preds = model(inputs)\n",
    "    rpred, ipred = preds.chunk(2, dim=1)\n",
    "    rtar, itar = targets.chunk(2, dim=1)\n",
    "    loss = criterion(rpred, rtar) + criterion(ipred, itar)\n",
    "\n",
    "    # Get computation history\n",
    "    history = model.denoiser.state_history\n",
    "    T = len(history)\n",
    "    M = min(truncation_steps, T)\n",
    "    \n",
    "    # Initialize gradients\n",
    "    alpha_list = [p for n, p in model.named_parameters() if 'alphas' in n]\n",
    "    alpha_indices = {p: idx for idx, p in enumerate(alpha_list)}\n",
    "    grad_alpha = [torch.zeros_like(p) for p in alpha_list]\n",
    "    \n",
    "    # Initialize lambda with proper gradient handling\n",
    "    if T == 0:\n",
    "        return grad_alpha, loss.item()\n",
    "    \n",
    "    outputs = history[-1]['outputs']\n",
    "    lambda_t = torch.autograd.grad(\n",
    "        loss, outputs, \n",
    "        retain_graph=True, \n",
    "        allow_unused=True\n",
    "    )\n",
    "    \n",
    "    # Replace None in lambda_t with zeros\n",
    "    lambda_t = list(lambda_t)\n",
    "    for i in range(len(lambda_t)):\n",
    "        if lambda_t[i] is None:\n",
    "            lambda_t[i] = torch.zeros_like(outputs[i])\n",
    "    \n",
    "    # Reverse through truncated steps\n",
    "    for t in reversed(range(max(0, T-M), T)):\n",
    "        state = history[t]\n",
    "        current_outputs = state['outputs']\n",
    "        current_alpha = state['alpha']\n",
    "\n",
    "        # Compute gradients with allow_unused=True\n",
    "        A = torch.autograd.grad(\n",
    "            current_outputs, current_alpha, \n",
    "            grad_outputs=lambda_t, \n",
    "            retain_graph=True, \n",
    "            allow_unused=True\n",
    "        )\n",
    "        B = torch.autograd.grad(\n",
    "            current_outputs, current_outputs, \n",
    "            grad_outputs=lambda_t, \n",
    "            retain_graph=True, \n",
    "            allow_unused=True\n",
    "        )\n",
    "        \n",
    "        # Update gradients and lambda with None checks\n",
    "        for g_a, a in zip(A, current_alpha):\n",
    "            if g_a is not None and a in alpha_indices:\n",
    "                grad_alpha[alpha_indices[a]] += g_a.detach()\n",
    "        # Update lambda_t for next iteration\n",
    "        lambda_t = [b.detach() if b is not None else None for b in B]\n",
    "        # Replace None in lambda_t with zeros for next iteration\n",
    "        for i in range(len(lambda_t)):\n",
    "            if lambda_t[i] is None:\n",
    "                lambda_t[i] = torch.zeros_like(current_outputs[i])\n",
    "\n",
    "    return grad_alpha, loss.item()\n",
    "\n",
    "def truncated_rad_step(model, train_batch, val_batch, w_optimizer, alpha_optimizer, \n",
    "                      criterion, truncation_steps=3):\n",
    "    # Train on current batch\n",
    "    real_in_t, imag_in_t, real_tar_t, imag_tar_t = train_batch\n",
    "    real_in_t = real_in_t.unsqueeze(1).to(device)\n",
    "    imag_in_t = imag_in_t.unsqueeze(1).to(device)\n",
    "    inputs_t = torch.cat([real_in_t, imag_in_t], dim=1)\n",
    "    \n",
    "    w_optimizer.zero_grad()\n",
    "    preds_t = model(inputs_t)\n",
    "    rpred_t, ipred_t = preds_t.chunk(2, dim=1)\n",
    "    rtar_t, itar_t = real_tar_t.unsqueeze(1).to(device), imag_tar_t.unsqueeze(1).to(device)\n",
    "    loss_train = criterion(rpred_t, rtar_t) + criterion(ipred_t, itar_t)\n",
    "    loss_train.backward()\n",
    "    w_optimizer.step()\n",
    "\n",
    "    # Compute truncated gradients for alpha\n",
    "    grad_alpha, val_loss = compute_truncated_grad(model, val_batch, criterion, truncation_steps)\n",
    "    \n",
    "    # Update alpha parameters\n",
    "    alpha_optimizer.zero_grad()\n",
    "    for p, g in zip([p for n, p in model.named_parameters() if 'alphas' in n], grad_alpha):\n",
    "        if g is not None:\n",
    "            if p.grad is None:\n",
    "                p.grad = g.to(device)\n",
    "            else:\n",
    "                p.grad += g.to(device)\n",
    "    alpha_optimizer.step()\n",
    "\n",
    "    return loss_train.item(), val_loss\n",
    "\n",
    "# ============ Modified Training Function ============\n",
    "def train_truncated_rad(model, train_loader, val_loader, test_loader, w_optimizer, \n",
    "                       alpha_optimizer, criterion, epochs=20, truncation_steps=3,\n",
    "                       test_interval=50):\n",
    "    from itertools import cycle\n",
    "    val_iter = cycle(val_loader)\n",
    "    \n",
    "    # Initialize tracking variables\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    test_losses = {'epochs': [], 'values': []}\n",
    "    all_epochs = []\n",
    "    start_time = time()\n",
    "    \n",
    "    # For learning rate tracking\n",
    "    lr_history = {'w_lr': [], 'alpha_lr': []}\n",
    "    \n",
    "    # For gradient norm tracking\n",
    "    grad_norms = {\n",
    "        'weight': defaultdict(list),\n",
    "        'alpha': defaultdict(list)\n",
    "    }\n",
    "    \n",
    "    # For architecture visualization\n",
    "    alpha_history = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_start = time()\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "        total_val_loss = 0.0\n",
    "        \n",
    "        # Store current learning rates\n",
    "        lr_history['w_lr'].append(w_optimizer.param_groups[0]['lr'])\n",
    "        lr_history['alpha_lr'].append(alpha_optimizer.param_groups[0]['lr'])\n",
    "        \n",
    "        for train_batch in train_loader:\n",
    "            val_batch = next(val_iter)\n",
    "            train_loss, val_loss = truncated_rad_step(\n",
    "                model, train_batch, val_batch,\n",
    "                w_optimizer, alpha_optimizer,\n",
    "                criterion, truncation_steps\n",
    "            )\n",
    "            total_train_loss += train_loss\n",
    "            total_val_loss += val_loss\n",
    "        \n",
    "        # Record gradient norms\n",
    "        with torch.no_grad():\n",
    "            for name, param in model.named_parameters():\n",
    "                if param.grad is not None:\n",
    "                    norm = param.grad.norm().item()\n",
    "                    if 'alphas' in name:\n",
    "                        grad_norms['alpha'][name].append(norm)\n",
    "                    else:\n",
    "                        grad_norms['weight'][name].append(norm)\n",
    "        \n",
    "        # Store alpha values for visualization\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            alphas = {}\n",
    "            for name, param in model.named_parameters():\n",
    "                if 'alphas' in name:\n",
    "                    edge_num = name.split('.')[1]\n",
    "                    alphas[edge_num] = F.softmax(param, dim=-1).detach().cpu().numpy()[0]\n",
    "            alpha_history.append((epoch+1, alphas))\n",
    "        \n",
    "        # Calculate epoch metrics\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        avg_val_loss = total_val_loss / len(train_loader)\n",
    "        \n",
    "        # Store metrics with small offset to avoid log(0)\n",
    "        train_losses.append(avg_train_loss + 1e-12)\n",
    "        val_losses.append(avg_val_loss + 1e-12)\n",
    "        all_epochs.append(epoch+1)\n",
    "        \n",
    "        # Periodic testing and visualization\n",
    "        if (epoch+1) % test_interval == 0 or (epoch+1) == epochs:\n",
    "            test_loss = evaluate(model, test_loader, criterion)\n",
    "            test_losses['epochs'].append(epoch+1)\n",
    "            test_losses['values'].append(test_loss + 1e-12)\n",
    "            print(f\"Test Loss @ Epoch {epoch+1}: {test_loss:.4f}\")\n",
    "            \n",
    "            # Plot channel estimates\n",
    "            plot_channel_estimates(model, test_loader, epoch+1)\n",
    "        \n",
    "        # Print and plot\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Time: {time()-epoch_start:.1f}s | \"\n",
    "              f\"Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "        \n",
    "        if (epoch+1) % 10 == 0:\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                plot_losses(all_epochs, train_losses, val_losses, test_losses)\n",
    "                plot_learning_rates(lr_history)\n",
    "                plot_gradient_norms(grad_norms)\n",
    "                \n",
    "                for epoch_num, alphas in alpha_history:\n",
    "                    plot_architecture(alphas, epoch_num)\n",
    "                alpha_history = []\n",
    "    \n",
    "    # Final plots\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        plot_losses(all_epochs, train_losses, val_losses, test_losses)\n",
    "        plot_learning_rates(lr_history)\n",
    "        plot_gradient_norms(grad_norms)\n",
    "    print(f\"Total training time: {(time()-start_time)/3600:.2f} hours\")\n",
    "    \n",
    "    return train_losses, val_losses, test_losses\n",
    "\n",
    "# ============ Main Execution ============\n",
    "if __name__ == \"__main__\":\n",
    "    model = FullModel().to(device)\n",
    "    \n",
    "    # Separate parameters\n",
    "    alpha_params = [p for n, p in model.named_parameters() if 'alphas' in n]\n",
    "    w_params = [p for n, p in model.named_parameters() if 'alphas' not in n]\n",
    "    \n",
    "    # Optimizers\n",
    "    w_optim = optim.Adam(w_params, lr=0.01)\n",
    "    alpha_optim = optim.Adam(alpha_params, lr=0.003)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    print(\"Starting training with Truncated RAD...\")\n",
    "    train_losses, val_losses, test_losses = train_truncated_rad(\n",
    "        model, train_loader, val_loader, test_loader,\n",
    "        w_optim, alpha_optim, criterion,\n",
    "        epochs=100, truncation_steps=50, test_interval=50\n",
    "    )\n",
    "    \n",
    "    # Final evaluation and saving\n",
    "    test_loss = evaluate(model, test_loader, criterion)\n",
    "    print(f\"Final Test Loss: {test_loss:.4f}\")\n",
    "    torch.save(model.state_dict(), \"final_model.pth\")\n",
    "    print(\"Model saved as final_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
