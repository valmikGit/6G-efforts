{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d063e444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Failed to load yDL_10dB_40k_150pilots_ipjp.mat with h5py. Trying scipy.io.loadmat...\n",
      "Loaded yDL_10dB_40k_150pilots_ipjp.mat using scipy.io.loadmat.\n",
      "Loaded PsiDL_10dB_40k_150pilots_ipjp.mat using h5py.\n",
      "Failed to load hDL_10dB_40k_150pilots_ipjp.mat with h5py. Trying scipy.io.loadmat...\n",
      "Loaded hDL_10dB_40k_150pilots_ipjp.mat using scipy.io.loadmat.\n",
      "Failed to load sigma2DL_10dB_40k_150pilots_ipjp.mat with h5py. Trying scipy.io.loadmat...\n",
      "Loaded sigma2DL_10dB_40k_150pilots_ipjp.mat using scipy.io.loadmat.\n",
      "y_complex_np shape: (40000, 150)\n",
      "psi_real_np shape: (40000, 512, 150)\n",
      "psi_imag_np shape: (40000, 512, 150)\n",
      "h_complex_np shape: (40000, 512)\n",
      "sigma2_np shape: (40000,)\n",
      "Processing SBL batch 1/40\n",
      "Processing SBL batch 2/40\n",
      "Processing SBL batch 3/40\n",
      "Processing SBL batch 4/40\n",
      "Processing SBL batch 5/40\n",
      "Processing SBL batch 6/40\n",
      "Processing SBL batch 7/40\n",
      "Processing SBL batch 8/40\n",
      "Processing SBL batch 9/40\n",
      "Processing SBL batch 10/40\n",
      "Processing SBL batch 11/40\n",
      "Processing SBL batch 12/40\n",
      "Processing SBL batch 13/40\n",
      "Processing SBL batch 14/40\n",
      "Processing SBL batch 15/40\n",
      "Processing SBL batch 16/40\n",
      "Processing SBL batch 17/40\n",
      "Processing SBL batch 18/40\n",
      "Processing SBL batch 19/40\n",
      "Processing SBL batch 20/40\n",
      "Processing SBL batch 21/40\n",
      "Processing SBL batch 22/40\n",
      "Processing SBL batch 23/40\n",
      "Processing SBL batch 24/40\n",
      "Processing SBL batch 25/40\n",
      "Processing SBL batch 26/40\n",
      "Processing SBL batch 27/40\n",
      "Processing SBL batch 28/40\n",
      "Processing SBL batch 29/40\n",
      "Processing SBL batch 30/40\n",
      "Processing SBL batch 31/40\n",
      "Processing SBL batch 32/40\n",
      "Processing SBL batch 33/40\n",
      "Processing SBL batch 34/40\n",
      "Processing SBL batch 35/40\n",
      "Processing SBL batch 36/40\n",
      "Processing SBL batch 37/40\n",
      "Processing SBL batch 38/40\n",
      "Processing SBL batch 39/40\n",
      "Processing SBL batch 40/40\n",
      "SBL estimation completed!\n",
      "Starting training with Truncated RAD...\n",
      "Epoch 1/100 | Time: 34.3s | Train Loss: 0.6960 | Val Loss: 0.6914\n",
      "Epoch 2/100 | Time: 34.4s | Train Loss: 0.4299 | Val Loss: 0.4329\n",
      "Epoch 3/100 | Time: 34.3s | Train Loss: 0.3378 | Val Loss: 0.3418\n",
      "Epoch 4/100 | Time: 34.3s | Train Loss: 0.3068 | Val Loss: 0.3099\n",
      "Epoch 5/100 | Time: 34.3s | Train Loss: 0.2699 | Val Loss: 0.2748\n",
      "Epoch 6/100 | Time: 34.4s | Train Loss: 0.2550 | Val Loss: 0.2607\n",
      "Epoch 7/100 | Time: 34.3s | Train Loss: 0.2545 | Val Loss: 0.2605\n",
      "Epoch 8/100 | Time: 34.3s | Train Loss: 0.2404 | Val Loss: 0.2487\n",
      "Epoch 9/100 | Time: 34.4s | Train Loss: 0.2258 | Val Loss: 0.2290\n",
      "Epoch 10/100 | Time: 34.6s | Train Loss: 0.2269 | Val Loss: 0.2288\n",
      "Epoch 11/100 | Time: 34.8s | Train Loss: 0.2197 | Val Loss: 0.2197\n",
      "Epoch 12/100 | Time: 34.8s | Train Loss: 0.2125 | Val Loss: 0.2190\n",
      "Epoch 13/100 | Time: 34.4s | Train Loss: 0.2102 | Val Loss: 0.2161\n",
      "Epoch 14/100 | Time: 34.2s | Train Loss: 0.2145 | Val Loss: 0.2158\n",
      "Epoch 15/100 | Time: 34.3s | Train Loss: 0.2010 | Val Loss: 0.2045\n",
      "Epoch 16/100 | Time: 34.3s | Train Loss: 0.2094 | Val Loss: 0.2163\n",
      "Epoch 17/100 | Time: 34.3s | Train Loss: 0.2018 | Val Loss: 0.2066\n",
      "Epoch 18/100 | Time: 34.3s | Train Loss: 0.2043 | Val Loss: 0.2096\n",
      "Epoch 19/100 | Time: 34.4s | Train Loss: 0.1952 | Val Loss: 0.2019\n",
      "Epoch 20/100 | Time: 34.3s | Train Loss: 0.1938 | Val Loss: 0.1976\n",
      "Epoch 21/100 | Time: 34.3s | Train Loss: 0.1925 | Val Loss: 0.1984\n",
      "Epoch 22/100 | Time: 34.4s | Train Loss: 0.1786 | Val Loss: 0.1815\n",
      "Epoch 23/100 | Time: 34.4s | Train Loss: 0.1842 | Val Loss: 0.1874\n",
      "Epoch 24/100 | Time: 34.4s | Train Loss: 0.1912 | Val Loss: 0.1963\n",
      "Epoch 25/100 | Time: 34.9s | Train Loss: 0.1841 | Val Loss: 0.1861\n",
      "Epoch 26/100 | Time: 34.9s | Train Loss: 0.1748 | Val Loss: 0.1790\n",
      "Epoch 27/100 | Time: 34.8s | Train Loss: 0.1792 | Val Loss: 0.1807\n",
      "Epoch 28/100 | Time: 34.9s | Train Loss: 0.1772 | Val Loss: 0.1828\n",
      "Epoch 29/100 | Time: 35.0s | Train Loss: 0.1794 | Val Loss: 0.1844\n",
      "Epoch 30/100 | Time: 34.6s | Train Loss: 0.1727 | Val Loss: 0.1824\n",
      "Epoch 31/100 | Time: 34.7s | Train Loss: 0.1718 | Val Loss: 0.1763\n",
      "Epoch 32/100 | Time: 34.5s | Train Loss: 0.1699 | Val Loss: 0.1750\n",
      "Epoch 33/100 | Time: 34.5s | Train Loss: 0.1772 | Val Loss: 0.1802\n",
      "Epoch 34/100 | Time: 34.8s | Train Loss: 0.1632 | Val Loss: 0.1639\n",
      "Epoch 35/100 | Time: 34.6s | Train Loss: 0.2061 | Val Loss: 0.2076\n",
      "Epoch 36/100 | Time: 34.5s | Train Loss: 0.1794 | Val Loss: 0.1824\n",
      "Epoch 37/100 | Time: 34.6s | Train Loss: 0.5223 | Val Loss: 0.5093\n",
      "Epoch 38/100 | Time: 34.7s | Train Loss: 0.8890 | Val Loss: 0.8865\n",
      "Epoch 39/100 | Time: 34.8s | Train Loss: 0.8934 | Val Loss: 0.8912\n",
      "Epoch 40/100 | Time: 34.6s | Train Loss: 0.8956 | Val Loss: 0.8941\n",
      "Epoch 41/100 | Time: 34.6s | Train Loss: 0.8956 | Val Loss: 0.8942\n",
      "Epoch 42/100 | Time: 34.7s | Train Loss: 0.8956 | Val Loss: 0.8944\n",
      "Epoch 43/100 | Time: 34.6s | Train Loss: 0.8956 | Val Loss: 0.8940\n",
      "Epoch 44/100 | Time: 34.7s | Train Loss: 0.8956 | Val Loss: 0.8944\n",
      "Epoch 45/100 | Time: 34.9s | Train Loss: 0.8956 | Val Loss: 0.8941\n",
      "Epoch 46/100 | Time: 35.0s | Train Loss: 0.8956 | Val Loss: 0.8944\n",
      "Epoch 47/100 | Time: 35.0s | Train Loss: 0.8956 | Val Loss: 0.8943\n",
      "Epoch 48/100 | Time: 34.7s | Train Loss: 0.8956 | Val Loss: 0.8940\n",
      "Epoch 49/100 | Time: 34.8s | Train Loss: 0.8956 | Val Loss: 0.8945\n",
      "Test Loss @ Epoch 50: 0.4505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_107862/2667565195.py:94: UserWarning: constrained_layout not applied because axes sizes collapsed to zero.  Try making figure larger or axes decorations smaller.\n",
      "  plt.savefig(f\"channel_estimates/epoch_{epoch}_example_{i}.png\")\n",
      "/tmp/ipykernel_107862/2667565195.py:94: UserWarning: constrained_layout not applied because axes sizes collapsed to zero.  Try making figure larger or axes decorations smaller.\n",
      "  plt.savefig(f\"channel_estimates/epoch_{epoch}_example_{i}.png\")\n",
      "/tmp/ipykernel_107862/2667565195.py:94: UserWarning: constrained_layout not applied because axes sizes collapsed to zero.  Try making figure larger or axes decorations smaller.\n",
      "  plt.savefig(f\"channel_estimates/epoch_{epoch}_example_{i}.png\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100 | Time: 48.8s | Train Loss: 0.8956 | Val Loss: 0.8938\n",
      "Epoch 51/100 | Time: 34.7s | Train Loss: 0.8955 | Val Loss: 0.8942\n",
      "Epoch 52/100 | Time: 34.5s | Train Loss: 0.8981 | Val Loss: 0.8947\n",
      "Epoch 53/100 | Time: 34.2s | Train Loss: 0.8956 | Val Loss: 0.8922\n",
      "Epoch 54/100 | Time: 34.0s | Train Loss: 0.8956 | Val Loss: 0.8925\n",
      "Epoch 55/100 | Time: 34.0s | Train Loss: 0.8956 | Val Loss: 0.8920\n",
      "Epoch 56/100 | Time: 34.1s | Train Loss: 0.8956 | Val Loss: 0.8919\n",
      "Epoch 57/100 | Time: 34.1s | Train Loss: 0.8956 | Val Loss: 0.8923\n",
      "Epoch 58/100 | Time: 34.2s | Train Loss: 0.8956 | Val Loss: 0.8924\n",
      "Epoch 59/100 | Time: 34.2s | Train Loss: 0.8956 | Val Loss: 0.8922\n",
      "Epoch 60/100 | Time: 34.3s | Train Loss: 0.8956 | Val Loss: 0.8924\n",
      "Epoch 61/100 | Time: 34.4s | Train Loss: 0.8956 | Val Loss: 0.8922\n",
      "Epoch 62/100 | Time: 34.4s | Train Loss: 0.8956 | Val Loss: 0.8921\n",
      "Epoch 63/100 | Time: 34.4s | Train Loss: 0.8956 | Val Loss: 0.8924\n",
      "Epoch 64/100 | Time: 34.4s | Train Loss: 0.8956 | Val Loss: 0.8925\n",
      "Epoch 65/100 | Time: 34.4s | Train Loss: 0.8956 | Val Loss: 0.8924\n",
      "Epoch 66/100 | Time: 34.1s | Train Loss: 0.8956 | Val Loss: 0.8923\n",
      "Epoch 67/100 | Time: 34.1s | Train Loss: 0.8956 | Val Loss: 0.8923\n",
      "Epoch 68/100 | Time: 34.0s | Train Loss: 0.8956 | Val Loss: 0.8921\n",
      "Epoch 69/100 | Time: 33.9s | Train Loss: 0.8956 | Val Loss: 0.8924\n",
      "Epoch 70/100 | Time: 34.0s | Train Loss: 0.8956 | Val Loss: 0.8923\n",
      "Epoch 71/100 | Time: 33.9s | Train Loss: 0.8956 | Val Loss: 0.8923\n",
      "Epoch 72/100 | Time: 34.2s | Train Loss: 0.8956 | Val Loss: 0.8920\n",
      "Epoch 73/100 | Time: 34.3s | Train Loss: 0.8956 | Val Loss: 0.8923\n",
      "Epoch 74/100 | Time: 34.5s | Train Loss: 0.8956 | Val Loss: 0.8924\n",
      "Epoch 75/100 | Time: 34.4s | Train Loss: 0.8956 | Val Loss: 0.8922\n",
      "Epoch 76/100 | Time: 34.6s | Train Loss: 0.8956 | Val Loss: 0.8924\n",
      "Epoch 77/100 | Time: 34.3s | Train Loss: 0.8956 | Val Loss: 0.8922\n",
      "Epoch 78/100 | Time: 34.2s | Train Loss: 0.8956 | Val Loss: 0.8921\n",
      "Epoch 79/100 | Time: 34.5s | Train Loss: 0.8956 | Val Loss: 0.8924\n",
      "Epoch 80/100 | Time: 34.3s | Train Loss: 0.8956 | Val Loss: 0.8925\n",
      "Epoch 81/100 | Time: 34.0s | Train Loss: 0.8956 | Val Loss: 0.8922\n",
      "Epoch 82/100 | Time: 33.9s | Train Loss: 0.8956 | Val Loss: 0.8926\n",
      "Epoch 83/100 | Time: 33.9s | Train Loss: 0.8956 | Val Loss: 0.8920\n",
      "Epoch 84/100 | Time: 33.9s | Train Loss: 0.8956 | Val Loss: 0.8922\n",
      "Epoch 85/100 | Time: 34.0s | Train Loss: 0.8956 | Val Loss: 0.8927\n",
      "Epoch 86/100 | Time: 34.4s | Train Loss: 0.8956 | Val Loss: 0.8921\n",
      "Epoch 87/100 | Time: 34.9s | Train Loss: 0.8956 | Val Loss: 0.8921\n",
      "Epoch 88/100 | Time: 34.7s | Train Loss: 0.8956 | Val Loss: 0.8921\n",
      "Epoch 89/100 | Time: 34.7s | Train Loss: 0.8956 | Val Loss: 0.8926\n",
      "Epoch 90/100 | Time: 34.6s | Train Loss: 0.8956 | Val Loss: 0.8923\n",
      "Epoch 91/100 | Time: 34.4s | Train Loss: 0.8956 | Val Loss: 0.8922\n",
      "Epoch 92/100 | Time: 34.7s | Train Loss: 0.8956 | Val Loss: 0.8923\n",
      "Epoch 93/100 | Time: 34.4s | Train Loss: 0.8956 | Val Loss: 0.8922\n",
      "Epoch 94/100 | Time: 34.6s | Train Loss: 0.8956 | Val Loss: 0.8923\n",
      "Epoch 95/100 | Time: 34.5s | Train Loss: 0.8956 | Val Loss: 0.8922\n",
      "Epoch 96/100 | Time: 34.4s | Train Loss: 0.8956 | Val Loss: 0.8926\n",
      "Epoch 97/100 | Time: 34.3s | Train Loss: 0.8956 | Val Loss: 0.8922\n",
      "Epoch 98/100 | Time: 34.3s | Train Loss: 0.8956 | Val Loss: 0.8923\n",
      "Epoch 99/100 | Time: 34.4s | Train Loss: 0.8956 | Val Loss: 0.8923\n",
      "Test Loss @ Epoch 100: 0.4506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_107862/2667565195.py:94: UserWarning: constrained_layout not applied because axes sizes collapsed to zero.  Try making figure larger or axes decorations smaller.\n",
      "  plt.savefig(f\"channel_estimates/epoch_{epoch}_example_{i}.png\")\n",
      "/tmp/ipykernel_107862/2667565195.py:94: UserWarning: constrained_layout not applied because axes sizes collapsed to zero.  Try making figure larger or axes decorations smaller.\n",
      "  plt.savefig(f\"channel_estimates/epoch_{epoch}_example_{i}.png\")\n",
      "/tmp/ipykernel_107862/2667565195.py:94: UserWarning: constrained_layout not applied because axes sizes collapsed to zero.  Try making figure larger or axes decorations smaller.\n",
      "  plt.savefig(f\"channel_estimates/epoch_{epoch}_example_{i}.png\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100 | Time: 48.6s | Train Loss: 0.8956 | Val Loss: 0.8923\n",
      "Total training time: 0.97 hours\n",
      "Final Test Loss: 0.4506\n",
      "Model saved as final_model.pth\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import h5py\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from time import time\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "\n",
    "# ============ Visualization Setup ============\n",
    "plt.ioff()\n",
    "plt.rcParams['figure.constrained_layout.use'] = True\n",
    "os.makedirs(\"progress_plots\", exist_ok=True)\n",
    "os.makedirs(\"architecture_plots\", exist_ok=True)\n",
    "os.makedirs(\"channel_estimates\", exist_ok=True)\n",
    "\n",
    "def plot_losses(epochs, train_losses, val_losses, test_losses=None):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6), constrained_layout=True)\n",
    "        \n",
    "        # Training and Validation Loss\n",
    "        ax1.plot(epochs, train_losses, label='Train Loss')\n",
    "        ax1.plot(epochs, val_losses, label='Val Loss')\n",
    "        ax1.set_title('Training & Validation Loss', fontsize=12)\n",
    "        ax1.set_xlabel('Epochs', fontsize=10)\n",
    "        ax1.set_ylabel('MSE Loss', fontsize=10)\n",
    "        if all(y > 0 for y in train_losses + val_losses):\n",
    "            ax1.set_yscale('log')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True)\n",
    "\n",
    "        # Test Loss if available\n",
    "        if test_losses:\n",
    "            ax2.plot(test_losses['epochs'], test_losses['values'], 'r-')\n",
    "            ax2.set_title('Test Loss Progression', fontsize=12)\n",
    "            ax2.set_xlabel('Epochs', fontsize=10)\n",
    "            ax2.set_ylabel('MSE Loss', fontsize=10)\n",
    "            if all(y > 0 for y in test_losses['values']):\n",
    "                ax2.set_yscale('log')\n",
    "            ax2.grid(True)\n",
    "\n",
    "        plt.savefig(f\"progress_plots/losses_{int(time())}.png\")\n",
    "        plt.close()\n",
    "\n",
    "def plot_architecture(alphas, epoch):\n",
    "    \"\"\"Plot the evolution of alpha parameters\"\"\"\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        fig = plt.figure(figsize=(18, 16), constrained_layout=True)\n",
    "        keys = sorted(alphas.keys())\n",
    "        \n",
    "        for i, (edge, alpha) in enumerate(alphas.items()):\n",
    "            ax = fig.add_subplot(4, 2, i+1)  # 4 rows, 2 columns\n",
    "            ax.bar(range(len(alpha)), alpha, width=0.6)\n",
    "            ax.set_title(f'Edge {edge} Alpha Values', fontsize=10)\n",
    "            ax.set_xlabel('Operation', fontsize=8)\n",
    "            ax.set_ylabel('Weight', fontsize=8)\n",
    "            ax.set_xticks(range(len(alpha)))\n",
    "            ax.set_xticklabels(list(OPS.keys()), rotation=60, ha='right', fontsize=7)\n",
    "            ax.tick_params(axis='y', labelsize=7)\n",
    "            \n",
    "        plt.savefig(f\"architecture_plots/alpha_epoch_{epoch}.png\")\n",
    "        plt.close()\n",
    "\n",
    "def plot_channel_estimates(model, test_loader, epoch, num_examples=3):\n",
    "    \"\"\"Plot example channel estimates\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (real_in, imag_in, real_tar, imag_tar) in enumerate(test_loader):\n",
    "            if i >= num_examples:\n",
    "                break\n",
    "            inputs = torch.cat([real_in.unsqueeze(1), imag_in.unsqueeze(1)], dim=1).to(device)\n",
    "            preds = model(inputs)\n",
    "            rpred, ipred = preds.chunk(2, dim=1)\n",
    "            \n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5), constrained_layout=True)\n",
    "            \n",
    "            ax1.plot(real_tar[0].numpy(), label='True Real')\n",
    "            ax1.plot(rpred[0].cpu().numpy(), label='Predicted Real')\n",
    "            ax1.set_title('Real Component', fontsize=10)\n",
    "            ax1.legend()\n",
    "            \n",
    "            ax2.plot(imag_tar[0].numpy(), label='True Imag')\n",
    "            ax2.plot(ipred[0].cpu().numpy(), label='Predicted Imag')\n",
    "            ax2.set_title('Imaginary Component', fontsize=10)\n",
    "            ax2.legend()\n",
    "            \n",
    "            plt.savefig(f\"channel_estimates/epoch_{epoch}_example_{i}.png\")\n",
    "            plt.close()\n",
    "\n",
    "def plot_learning_rates(lr_history):\n",
    "    \"\"\"Plot learning rate evolution\"\"\"\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5), constrained_layout=True)\n",
    "        \n",
    "        ax1.plot(lr_history['w_lr'], label='Weight LR')\n",
    "        ax1.set_title('Weight Learning Rate', fontsize=10)\n",
    "        ax1.set_xlabel('Epoch', fontsize=8)\n",
    "        ax1.set_ylabel('Learning Rate', fontsize=8)\n",
    "        \n",
    "        ax2.plot(lr_history['alpha_lr'], label='Alpha LR')\n",
    "        ax2.set_title('Alpha Learning Rate', fontsize=10)\n",
    "        ax2.set_xlabel('Epoch', fontsize=8)\n",
    "        ax2.set_ylabel('Learning Rate', fontsize=8)\n",
    "        \n",
    "        plt.savefig(f\"progress_plots/learning_rates_{int(time())}.png\")\n",
    "        plt.close()\n",
    "\n",
    "def plot_gradient_norms(grad_norms):\n",
    "    \"\"\"Plot gradient norms over time\"\"\"\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5), constrained_layout=True)\n",
    "        \n",
    "        for name, norms in grad_norms['weight'].items():\n",
    "            ax1.plot(norms, label=name)\n",
    "        ax1.set_title('Weight Gradient Norms', fontsize=10)\n",
    "        ax1.set_xlabel('Epoch', fontsize=8)\n",
    "        ax1.set_ylabel('Gradient Norm', fontsize=8)\n",
    "        if any(n > 0 for n in norms):\n",
    "            ax1.set_yscale('log')\n",
    "        ax1.legend(fontsize=7)\n",
    "        \n",
    "        for name, norms in grad_norms['alpha'].items():\n",
    "            ax2.plot(norms, label=name)\n",
    "        ax2.set_title('Alpha Gradient Norms', fontsize=10)\n",
    "        ax2.set_xlabel('Epoch', fontsize=8)\n",
    "        ax2.set_ylabel('Gradient Norm', fontsize=8)\n",
    "        if any(n > 0 for n in norms):\n",
    "            ax2.set_yscale('log')\n",
    "        ax2.legend(fontsize=7)\n",
    "        \n",
    "        plt.savefig(f\"progress_plots/gradient_norms_{int(time())}.png\")\n",
    "        plt.close()\n",
    "\n",
    "# ============ GPU Setup ============\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ============ Load .mat Files with Fallback ============\n",
    "def load_mat_file(file_path, var_name):\n",
    "    try:\n",
    "        with h5py.File(file_path, 'r') as f:\n",
    "            data = f[var_name][:]\n",
    "        print(f\"Loaded {file_path} using h5py.\")\n",
    "    except OSError:\n",
    "        print(f\"Failed to load {file_path} with h5py. Trying scipy.io.loadmat...\")\n",
    "        data = loadmat(file_path)[var_name]\n",
    "        print(f\"Loaded {file_path} using scipy.io.loadmat.\")\n",
    "    return data\n",
    "\n",
    "# ============ Load Data ============\n",
    "def load_data():\n",
    "    data_y = load_mat_file('yDL_10dB_40k_150pilots_ipjp.mat', 'yDL')\n",
    "    data_psi = load_mat_file('PsiDL_10dB_40k_150pilots_ipjp.mat', 'PsiDL')\n",
    "    data_h = load_mat_file('hDL_10dB_40k_150pilots_ipjp.mat', 'hDL')\n",
    "    data_sigma2 = load_mat_file('sigma2DL_10dB_40k_150pilots_ipjp.mat', 'sigma2DL')\n",
    "\n",
    "    y_complex_np = data_y[..., 0] + 1j * data_y[..., 1]\n",
    "    h_complex_np = data_h[..., 0] + 1j * data_h[..., 1]\n",
    "    \n",
    "    # Corrected transpose: (2,0,1) instead of (2,1,0)\n",
    "    psi_real_np = data_psi[0].transpose(2, 0, 1)  # Corrected shape: (40000, 512, 150)\n",
    "    psi_imag_np = data_psi[1].transpose(2, 0, 1)  # Corrected shape: (40000, 512, 150)\n",
    "    sigma2_np = data_sigma2.squeeze()  # Shape: (40000,)\n",
    "    \n",
    "    # Verify shapes\n",
    "    print(f\"y_complex_np shape: {y_complex_np.shape}\")        # (40000, 150)\n",
    "    print(f\"psi_real_np shape: {psi_real_np.shape}\")          # (40000, 512, 150)\n",
    "    print(f\"psi_imag_np shape: {psi_imag_np.shape}\")          # (40000, 512, 150)\n",
    "    print(f\"h_complex_np shape: {h_complex_np.shape}\")        # (40000, 512)\n",
    "    print(f\"sigma2_np shape: {sigma2_np.shape}\")              # (40000,)\n",
    "    \n",
    "    return y_complex_np, psi_real_np, psi_imag_np, h_complex_np, sigma2_np\n",
    "\n",
    "y_complex_np, psi_real_np, psi_imag_np, h_complex_np, sigma2_np = load_data()\n",
    "\n",
    "# ============ SBL Update Function (PyTorch) ============\n",
    "def sbl_update_batch(Psi, y, Gamma_init, sigma2):\n",
    "    \"\"\"\n",
    "    Psi: complex tensor [batch, M, N]  (M=512, N=150)\n",
    "    y: complex tensor [batch, N] \n",
    "    Gamma_init: real tensor [batch, M] (initial prior variances)\n",
    "    sigma2: real tensor [batch] (noise variances)\n",
    "    \"\"\"\n",
    "    # Compute Psi^H (Hermitian transpose) - [batch, N, M]\n",
    "    PsiH = torch.conj(Psi).permute(0, 2, 1)\n",
    "    \n",
    "    # Compute Rx_PsiH = diag(Gamma_init) * Psi^H - [batch, N, M]\n",
    "    Rx_PsiH = Gamma_init.unsqueeze(1) * PsiH\n",
    "    \n",
    "    # Compute A = Rx_PsiH @ Psi + sigma2 * I - [batch, N, N]\n",
    "    A = torch.matmul(Rx_PsiH, Psi)\n",
    "    I = torch.eye(A.size(-1), dtype=Psi.dtype, device=Psi.device)\n",
    "    A = A + sigma2.view(-1, 1, 1) * I.unsqueeze(0)\n",
    "    \n",
    "    # Compute inverse of A - [batch, N, N]\n",
    "    inv_A = torch.linalg.inv(A)\n",
    "    \n",
    "    # Compute z = diag(Gamma_init) @ Psi^H @ inv_A - [batch, M, N]\n",
    "    z = torch.matmul(Gamma_init.unsqueeze(2) * PsiH.permute(0, 2, 1), inv_A)\n",
    "    \n",
    "    # Compute posterior mean (channel estimate) - [batch, M]\n",
    "    mu = torch.matmul(z, y.unsqueeze(-1)).squeeze(-1)\n",
    "    \n",
    "    return mu\n",
    "\n",
    "# ============ Compute SBL Estimate in Batches ============\n",
    "num_samples = 40000\n",
    "batch_size = 1000\n",
    "h_SBL_complex = torch.empty((num_samples, 512), dtype=torch.cfloat, device=device)\n",
    "\n",
    "for start in range(0, num_samples, batch_size):\n",
    "    end = min(start + batch_size, num_samples)\n",
    "    print(f\"Processing SBL batch {start//batch_size + 1}/{(num_samples//batch_size)}\")\n",
    "    \n",
    "    # Prepare batch data\n",
    "    y_batch_np = y_complex_np[start:end]  # [batch, 150]\n",
    "    psi_real_batch = psi_real_np[start:end]  # [batch, 512, 150]\n",
    "    psi_imag_batch = psi_imag_np[start:end]  # [batch, 512, 150]\n",
    "    sigma2_batch = sigma2_np[start:end]  # [batch]\n",
    "    \n",
    "    # Convert to PyTorch tensors\n",
    "    y_batch = torch.tensor(y_batch_np, dtype=torch.cfloat, device=device)\n",
    "    Psi_batch = torch.tensor(psi_real_batch, dtype=torch.float, device=device) + \\\n",
    "                1j * torch.tensor(psi_imag_batch, dtype=torch.float, device=device)\n",
    "    sigma2_batch = torch.tensor(sigma2_batch, dtype=torch.float, device=device)\n",
    "    \n",
    "    # Initialize Gamma (prior variances) - [batch, 512]\n",
    "    Gamma_init = torch.ones((end - start, 512), dtype=torch.float, device=device)\n",
    "    \n",
    "    # Compute SBL estimate\n",
    "    h_est = sbl_update_batch(Psi_batch, y_batch, Gamma_init, sigma2_batch)\n",
    "    \n",
    "    # Store results\n",
    "    h_SBL_complex[start:end] = h_est\n",
    "\n",
    "print(\"SBL estimation completed!\")\n",
    "\n",
    "# Prepare tensors for dataset\n",
    "h_SBL_real, h_SBL_imag = h_SBL_complex.real, h_SBL_complex.imag\n",
    "h_real = torch.tensor(h_complex_np.real, dtype=torch.float32)\n",
    "h_imag = torch.tensor(h_complex_np.imag, dtype=torch.float32)\n",
    "\n",
    "# Move to CPU if needed for dataset creation\n",
    "if device.type == 'cuda':\n",
    "    h_SBL_real = h_SBL_real.cpu()\n",
    "    h_SBL_imag = h_SBL_imag.cpu()\n",
    "    h_real = h_real.cpu()\n",
    "    h_imag = h_imag.cpu()\n",
    "\n",
    "# ============ Dataset Split ============\n",
    "train_samples, val_samples, test_samples = 32000, 4000, 4000\n",
    "\n",
    "train_dataset = TensorDataset(\n",
    "    h_SBL_real[:train_samples], \n",
    "    h_SBL_imag[:train_samples],\n",
    "    h_real[:train_samples], \n",
    "    h_imag[:train_samples]\n",
    ")\n",
    "\n",
    "val_dataset = TensorDataset(\n",
    "    h_SBL_real[train_samples:train_samples+val_samples],\n",
    "    h_SBL_imag[train_samples:train_samples+val_samples],\n",
    "    h_real[train_samples:train_samples+val_samples],\n",
    "    h_imag[train_samples:train_samples+val_samples]\n",
    ")\n",
    "\n",
    "test_dataset = TensorDataset(\n",
    "    h_SBL_real[train_samples+val_samples:],\n",
    "    h_SBL_imag[train_samples+val_samples:],\n",
    "    h_real[train_samples+val_samples:],\n",
    "    h_imag[train_samples+val_samples:]\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# ============ Neural Architecture Components ============\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(2, 16, 3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(16, 32, 3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        return F.relu(self.conv2(x))\n",
    "\n",
    "OPS = {\n",
    "    'skip_connection': lambda C: nn.Sequential(\n",
    "        nn.Conv1d(C, C, 1, bias=False),\n",
    "        nn.BatchNorm1d(C)\n",
    "    ),\n",
    "    'zero': lambda C: nn.ZeroPad1d(0),\n",
    "    'conv_3x3': lambda C: nn.Conv1d(C, C, 3, padding=1, bias=False),\n",
    "    'sep_conv_3x3': lambda C: nn.Sequential(\n",
    "        nn.Conv1d(C, C, 3, padding=1, groups=C, bias=False),\n",
    "        nn.Conv1d(C, C, 1, bias=False),\n",
    "        nn.BatchNorm1d(C)\n",
    "    ),\n",
    "    'dil_conv_3x3': lambda C: nn.Conv1d(C, C, 3, padding=2, dilation=2, bias=False),\n",
    "}\n",
    "\n",
    "class DenoiseCell(nn.Module):\n",
    "    def __init__(self, C):\n",
    "        super().__init__()\n",
    "        self.C = C\n",
    "        self.num_edges = 8\n",
    "        self.num_ops = len(OPS)\n",
    "        self.alphas = nn.Parameter(torch.randn(self.num_edges, self.num_ops))\n",
    "        self.ops = nn.ModuleList([nn.ModuleList([op(C) for op in OPS.values()]) \n",
    "                                   for _ in range(self.num_edges)])\n",
    "        self.conv1x1 = nn.Conv1d(8*C, C, 1, bias=False)\n",
    "\n",
    "    def pad_and_concat(self, inputs):\n",
    "        max_size = max(inp.shape[2] for inp in inputs)\n",
    "        padded_inputs = [F.pad(inp, (0, max_size - inp.shape[2])) if inp.shape[2] < max_size else inp\n",
    "                         for inp in inputs]\n",
    "        return torch.cat(padded_inputs, dim=1)\n",
    "\n",
    "    def apply_ops(self, x, edge_idx):\n",
    "        weights = F.softmax(self.alphas[edge_idx], dim=-1)\n",
    "        return sum(w * op(x) for w, op in zip(weights, self.ops[edge_idx]))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        in0, in1 = inputs\n",
    "        \n",
    "        node0 = self.pad_and_concat([in0, in1])\n",
    "        node0 = F.relu(node0)\n",
    "        \n",
    "        node1 = F.relu(node0)\n",
    "        \n",
    "        node2 = self.pad_and_concat([node0, node1])\n",
    "        node2 = F.relu(node2)\n",
    "        \n",
    "        node3_inputs = self.pad_and_concat([node0, node1, node2])\n",
    "        \n",
    "        node3 = F.relu(self.conv1x1(node3_inputs))\n",
    "        return node3\n",
    "\n",
    "class DenoiseModule(nn.Module):\n",
    "    def __init__(self, C):\n",
    "        super().__init__()\n",
    "        self.cells = nn.ModuleList([DenoiseCell(C) for _ in range(10)])\n",
    "        self.state_history = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = [x, x]\n",
    "        self.state_history = []\n",
    "        for i in range(10):\n",
    "            if i == 0:\n",
    "                out = self.cells[i]([outputs[0], outputs[0]])\n",
    "            elif i == 1:\n",
    "                out = self.cells[i]([outputs[1], outputs[0]])\n",
    "            else:\n",
    "                out = self.cells[i]([outputs[-2], outputs[-1]])\n",
    "            outputs.append(out)\n",
    "            self.state_history.append({\n",
    "                'outputs': list(outputs),\n",
    "                'alpha': list(self.parameters())\n",
    "            })\n",
    "        return outputs[-1]\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Full connection layer (1x1 convolution)\n",
    "        self.fc = nn.Conv1d(32, 32, kernel_size=1)\n",
    "        \n",
    "        # First separable convolution block\n",
    "        self.sep_conv1 = nn.Sequential(\n",
    "            nn.Conv1d(32, 32, 3, padding=1, groups=32, bias=False),\n",
    "            nn.Conv1d(32, 32, 1, bias=False),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Second separable convolution block\n",
    "        self.sep_conv2 = nn.Sequential(\n",
    "            nn.Conv1d(32, 32, 3, padding=1, groups=32, bias=False),\n",
    "            nn.Conv1d(32, 16, 1, bias=False),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Final convolution layer\n",
    "        self.final_conv = nn.Conv1d(16, 2, 3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc(x))\n",
    "        x = self.sep_conv1(x)\n",
    "        x = self.sep_conv2(x)\n",
    "        return self.final_conv(x)\n",
    "\n",
    "class FullModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = FeatureExtractor()\n",
    "        self.denoiser = DenoiseModule(32)\n",
    "        self.decoder = Decoder()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.denoiser(x)\n",
    "        return self.decoder(x)\n",
    "\n",
    "# ============ Evaluation Function ============\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for real_in, imag_in, real_tar, imag_tar in loader:\n",
    "            inputs = torch.cat([real_in.unsqueeze(1), imag_in.unsqueeze(1)], dim=1).to(device)\n",
    "            targets = torch.cat([real_tar.unsqueeze(1), imag_tar.unsqueeze(1)], dim=1).to(device)\n",
    "            \n",
    "            preds = model(inputs)\n",
    "            loss = criterion(preds, targets)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# ============ Truncated RAD Implementation ============\n",
    "def compute_truncated_grad(model, val_batch, criterion, truncation_steps=3):\n",
    "    real_in, imag_in, real_tar, imag_tar = val_batch\n",
    "    real_in = real_in.unsqueeze(1).to(device)\n",
    "    imag_in = imag_in.unsqueeze(1).to(device)\n",
    "    inputs = torch.cat([real_in, imag_in], dim=1)\n",
    "    \n",
    "    real_tar = real_tar.unsqueeze(1).to(device)\n",
    "    imag_tar = imag_tar.unsqueeze(1).to(device)\n",
    "    targets = torch.cat([real_tar, imag_tar], dim=1)\n",
    "\n",
    "    # Forward pass through unrolled steps\n",
    "    preds = model(inputs)\n",
    "    rpred, ipred = preds.chunk(2, dim=1)\n",
    "    rtar, itar = targets.chunk(2, dim=1)\n",
    "    loss = criterion(rpred, rtar) + criterion(ipred, itar)\n",
    "\n",
    "    # Get computation history\n",
    "    history = model.denoiser.state_history\n",
    "    T = len(history)\n",
    "    M = min(truncation_steps, T)\n",
    "    \n",
    "    # Initialize gradients\n",
    "    alpha_list = [p for n, p in model.named_parameters() if 'alphas' in n]\n",
    "    alpha_indices = {p: idx for idx, p in enumerate(alpha_list)}\n",
    "    grad_alpha = [torch.zeros_like(p) for p in alpha_list]\n",
    "    \n",
    "    # Initialize lambda with proper gradient handling\n",
    "    if T == 0:\n",
    "        return grad_alpha, loss.item()\n",
    "    \n",
    "    outputs = history[-1]['outputs']\n",
    "    lambda_t = torch.autograd.grad(\n",
    "        loss, outputs, \n",
    "        retain_graph=True, \n",
    "        allow_unused=True\n",
    "    )\n",
    "    \n",
    "    # Replace None in lambda_t with zeros\n",
    "    lambda_t = list(lambda_t)\n",
    "    for i in range(len(lambda_t)):\n",
    "        if lambda_t[i] is None:\n",
    "            lambda_t[i] = torch.zeros_like(outputs[i])\n",
    "    \n",
    "    # Reverse through truncated steps\n",
    "    for t in reversed(range(max(0, T-M), T)):\n",
    "        state = history[t]\n",
    "        current_outputs = state['outputs']\n",
    "        current_alpha = state['alpha']\n",
    "\n",
    "        # Compute gradients with allow_unused=True\n",
    "        A = torch.autograd.grad(\n",
    "            current_outputs, current_alpha, \n",
    "            grad_outputs=lambda_t, \n",
    "            retain_graph=True, \n",
    "            allow_unused=True\n",
    "        )\n",
    "        B = torch.autograd.grad(\n",
    "            current_outputs, current_outputs, \n",
    "            grad_outputs=lambda_t, \n",
    "            retain_graph=True, \n",
    "            allow_unused=True\n",
    "        )\n",
    "        \n",
    "        # Update gradients and lambda with None checks\n",
    "        for g_a, a in zip(A, current_alpha):\n",
    "            if g_a is not None and a in alpha_indices:\n",
    "                grad_alpha[alpha_indices[a]] += g_a.detach()\n",
    "        # Update lambda_t for next iteration\n",
    "        lambda_t = [b.detach() if b is not None else None for b in B]\n",
    "        # Replace None in lambda_t with zeros for next iteration\n",
    "        for i in range(len(lambda_t)):\n",
    "            if lambda_t[i] is None:\n",
    "                lambda_t[i] = torch.zeros_like(current_outputs[i])\n",
    "\n",
    "    return grad_alpha, loss.item()\n",
    "\n",
    "def truncated_rad_step(model, train_batch, val_batch, w_optimizer, alpha_optimizer, \n",
    "                      criterion, truncation_steps=3):\n",
    "    # Train on current batch\n",
    "    real_in_t, imag_in_t, real_tar_t, imag_tar_t = train_batch\n",
    "    real_in_t = real_in_t.unsqueeze(1).to(device)\n",
    "    imag_in_t = imag_in_t.unsqueeze(1).to(device)\n",
    "    inputs_t = torch.cat([real_in_t, imag_in_t], dim=1)\n",
    "    \n",
    "    w_optimizer.zero_grad()\n",
    "    preds_t = model(inputs_t)\n",
    "    rpred_t, ipred_t = preds_t.chunk(2, dim=1)\n",
    "    rtar_t, itar_t = real_tar_t.unsqueeze(1).to(device), imag_tar_t.unsqueeze(1).to(device)\n",
    "    loss_train = criterion(rpred_t, rtar_t) + criterion(ipred_t, itar_t)\n",
    "    loss_train.backward()\n",
    "    w_optimizer.step()\n",
    "\n",
    "    # Compute truncated gradients for alpha\n",
    "    grad_alpha, val_loss = compute_truncated_grad(model, val_batch, criterion, truncation_steps)\n",
    "    \n",
    "    # Update alpha parameters\n",
    "    alpha_optimizer.zero_grad()\n",
    "    for p, g in zip([p for n, p in model.named_parameters() if 'alphas' in n], grad_alpha):\n",
    "        if g is not None:\n",
    "            if p.grad is None:\n",
    "                p.grad = g.to(device)\n",
    "            else:\n",
    "                p.grad += g.to(device)\n",
    "    alpha_optimizer.step()\n",
    "\n",
    "    return loss_train.item(), val_loss\n",
    "\n",
    "# ============ Modified Training Function ============\n",
    "def train_truncated_rad(model, train_loader, val_loader, test_loader, w_optimizer, \n",
    "                       alpha_optimizer, criterion, epochs=20, truncation_steps=3,\n",
    "                       test_interval=50):\n",
    "    from itertools import cycle\n",
    "    val_iter = cycle(val_loader)\n",
    "    \n",
    "    # Initialize tracking variables\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    test_losses = {'epochs': [], 'values': []}\n",
    "    all_epochs = []\n",
    "    start_time = time()\n",
    "    \n",
    "    # For learning rate tracking\n",
    "    lr_history = {'w_lr': [], 'alpha_lr': []}\n",
    "    \n",
    "    # For gradient norm tracking\n",
    "    grad_norms = {\n",
    "        'weight': defaultdict(list),\n",
    "        'alpha': defaultdict(list)\n",
    "    }\n",
    "    \n",
    "    # For architecture visualization\n",
    "    alpha_history = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_start = time()\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "        total_val_loss = 0.0\n",
    "        \n",
    "        # Store current learning rates\n",
    "        lr_history['w_lr'].append(w_optimizer.param_groups[0]['lr'])\n",
    "        lr_history['alpha_lr'].append(alpha_optimizer.param_groups[0]['lr'])\n",
    "        \n",
    "        for train_batch in train_loader:\n",
    "            val_batch = next(val_iter)\n",
    "            train_loss, val_loss = truncated_rad_step(\n",
    "                model, train_batch, val_batch,\n",
    "                w_optimizer, alpha_optimizer,\n",
    "                criterion, truncation_steps\n",
    "            )\n",
    "            total_train_loss += train_loss\n",
    "            total_val_loss += val_loss\n",
    "        \n",
    "        # Record gradient norms\n",
    "        with torch.no_grad():\n",
    "            for name, param in model.named_parameters():\n",
    "                if param.grad is not None:\n",
    "                    norm = param.grad.norm().item()\n",
    "                    if 'alphas' in name:\n",
    "                        grad_norms['alpha'][name].append(norm)\n",
    "                    else:\n",
    "                        grad_norms['weight'][name].append(norm)\n",
    "        \n",
    "        # Store alpha values for visualization\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            alphas = {}\n",
    "            for name, param in model.named_parameters():\n",
    "                if 'alphas' in name:\n",
    "                    edge_num = name.split('.')[1]\n",
    "                    alphas[edge_num] = F.softmax(param, dim=-1).detach().cpu().numpy()[0]\n",
    "            alpha_history.append((epoch+1, alphas))\n",
    "        \n",
    "        # Calculate epoch metrics\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        avg_val_loss = total_val_loss / len(train_loader)\n",
    "        \n",
    "        # Store metrics with small offset to avoid log(0)\n",
    "        train_losses.append(avg_train_loss + 1e-12)\n",
    "        val_losses.append(avg_val_loss + 1e-12)\n",
    "        all_epochs.append(epoch+1)\n",
    "        \n",
    "        # Periodic testing and visualization\n",
    "        if (epoch+1) % test_interval == 0 or (epoch+1) == epochs:\n",
    "            test_loss = evaluate(model, test_loader, criterion)\n",
    "            test_losses['epochs'].append(epoch+1)\n",
    "            test_losses['values'].append(test_loss + 1e-12)\n",
    "            print(f\"Test Loss @ Epoch {epoch+1}: {test_loss:.4f}\")\n",
    "            \n",
    "            # Plot channel estimates\n",
    "            plot_channel_estimates(model, test_loader, epoch+1)\n",
    "        \n",
    "        # Print and plot\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Time: {time()-epoch_start:.1f}s | \"\n",
    "              f\"Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "        \n",
    "        if (epoch+1) % 10 == 0:\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                plot_losses(all_epochs, train_losses, val_losses, test_losses)\n",
    "                plot_learning_rates(lr_history)\n",
    "                plot_gradient_norms(grad_norms)\n",
    "                \n",
    "                for epoch_num, alphas in alpha_history:\n",
    "                    plot_architecture(alphas, epoch_num)\n",
    "                alpha_history = []\n",
    "    \n",
    "    # Final plots\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        plot_losses(all_epochs, train_losses, val_losses, test_losses)\n",
    "        plot_learning_rates(lr_history)\n",
    "        plot_gradient_norms(grad_norms)\n",
    "    print(f\"Total training time: {(time()-start_time)/3600:.2f} hours\")\n",
    "    \n",
    "    return train_losses, val_losses, test_losses\n",
    "\n",
    "# ============ Main Execution ============\n",
    "if __name__ == \"__main__\":\n",
    "    model = FullModel().to(device)\n",
    "    \n",
    "    # Separate parameters\n",
    "    alpha_params = [p for n, p in model.named_parameters() if 'alphas' in n]\n",
    "    w_params = [p for n, p in model.named_parameters() if 'alphas' not in n]\n",
    "    \n",
    "    # Optimizers\n",
    "    w_optim = optim.Adam(w_params, lr=0.01)\n",
    "    alpha_optim = optim.Adam(alpha_params, lr=0.003)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    print(\"Starting training with Truncated RAD...\")\n",
    "    train_losses, val_losses, test_losses = train_truncated_rad(\n",
    "        model, train_loader, val_loader, test_loader,\n",
    "        w_optim, alpha_optim, criterion,\n",
    "        epochs=100, truncation_steps=50, test_interval=50\n",
    "    )\n",
    "    \n",
    "    # Final evaluation and saving\n",
    "    test_loss = evaluate(model, test_loader, criterion)\n",
    "    print(f\"Final Test Loss: {test_loss:.4f}\")\n",
    "    torch.save(model.state_dict(), \"final_model.pth\")\n",
    "    print(\"Model saved as final_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
