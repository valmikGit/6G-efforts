{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Generate synthetic dataset (y, psi, omega) assuming 10000 rows\n",
    "num_samples = 10000\n",
    "n, d = 150, 512  # Dimensions given in problem\n",
    "\n",
    "y = torch.randn(num_samples, n, 1)\n",
    "psi = torch.randn(num_samples, n, d)\n",
    "omega = torch.randn(num_samples, n, 1)\n",
    "\n",
    "# Compute Least Squares Estimate h_LS using Moore-Penrose pseudo-inverse\n",
    "h_LS = torch.linalg.pinv(psi) @ (y - omega)  # Shape: (num_samples, d, 1)\n",
    "h_LS = h_LS.squeeze(-1)  # Shape: (num_samples, d)\n",
    "\n",
    "# Prepare dataset\n",
    "train_dataset = TensorDataset(h_LS, h_LS)  # Input and output are both h_LS\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Define candidate operations for the search space\n",
    "OPS = {\n",
    "    'conv_3x3': lambda C: nn.Conv2d(C, C, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "    'conv_5x5': lambda C: nn.Conv2d(C, C, kernel_size=5, stride=1, padding=2, bias=False),\n",
    "    'identity': lambda C: nn.Identity(),\n",
    "    'skip_connection': lambda C: nn.Sequential(nn.Conv2d(C, C, 1, stride=1, bias=False), nn.BatchNorm2d(C)),\n",
    "    'zero': lambda C: nn.ZeroPad2d(0),\n",
    "}\n",
    "\n",
    "# Mixed operation layer with probability-based selection\n",
    "class MixedOp(nn.Module):\n",
    "    def __init__(self, C):\n",
    "        super().__init__()\n",
    "        self.ops = nn.ModuleList([op(C) for op in OPS.values()])\n",
    "        self.alphas = nn.Parameter(torch.randn(len(self.ops)))  # Learnable probabilities\n",
    "    \n",
    "    def forward(self, x):\n",
    "        weights = F.softmax(self.alphas, dim=0)  # Normalize with softmax\n",
    "        return sum(w * op(x) for w, op in zip(weights, self.ops))\n",
    "\n",
    "# Searchable Neural Network with architecture selection\n",
    "class SearchNetwork(nn.Module):\n",
    "    def __init__(self, C, num_layers=3):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([MixedOp(C) for _ in range(num_layers)])\n",
    "        self.output_layer = nn.Conv2d(C, C, kernel_size=1, stride=1, bias=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return self.output_layer(x)\n",
    "\n",
    "# Training function with truncated reverse-mode AD for NAS\n",
    "def train(model, train_loader, arch_optimizer, model_optimizer, criterion, unroll_steps=1):\n",
    "    model.train()\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.unsqueeze(1), y.unsqueeze(1)  # Add channel dimension for CNN layers\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        # Compute loss and update model parameters\n",
    "        model_optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        model_optimizer.step()\n",
    "        \n",
    "        # Architecture update using truncated differentiation\n",
    "        arch_optimizer.zero_grad()\n",
    "        with torch.no_grad():\n",
    "            temp_model = SearchNetwork(d).to(device)\n",
    "            temp_model.load_state_dict(model.state_dict())\n",
    "        for _ in range(unroll_steps):\n",
    "            temp_output = temp_model(x)\n",
    "            temp_loss = criterion(temp_output, y)\n",
    "            temp_loss.backward()\n",
    "        arch_optimizer.step()\n",
    "\n",
    "# Hyperparameters\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_layers = 3\n",
    "num_epochs = 20\n",
    "\n",
    "# Initialize model and optimizers\n",
    "model = SearchNetwork(d).to(device)\n",
    "arch_optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "model_optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Train model with NAS\n",
    "for epoch in range(num_epochs):\n",
    "    train(model, train_loader, arch_optimizer, model_optimizer, criterion)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} completed.\")\n",
    "\n",
    "# Extract final architecture based on highest probability operations\n",
    "def extract_final_architecture(model):\n",
    "    final_ops = []\n",
    "    for layer in model.layers:\n",
    "        best_op_idx = torch.argmax(layer.alphas).item()\n",
    "        best_op_name = list(OPS.keys())[best_op_idx]\n",
    "        final_ops.append(best_op_name)\n",
    "    return final_ops\n",
    "\n",
    "final_architecture = extract_final_architecture(model)\n",
    "print(\"Final Architecture:\", final_architecture)\n",
    "\n",
    "# Save the best model\n",
    "torch.save(model.state_dict(), \"best_model.pth\")\n",
    "\n",
    "print(\"Neural architecture search completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with real and imaginary separate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Generate synthetic dataset with complex values\n",
    "num_samples = 10000\n",
    "n, d = 150, 512  # Dimensions given in problem\n",
    "\n",
    "y_complex = torch.randn(num_samples, n, 1, dtype=torch.cfloat)\n",
    "psi_complex = torch.randn(num_samples, n, d, dtype=torch.cfloat)\n",
    "omega_complex = torch.randn(num_samples, n, 1, dtype=torch.cfloat)\n",
    "\n",
    "# Compute Least Squares Estimate h_LS using Moore-Penrose pseudo-inverse\n",
    "h_LS_complex = torch.linalg.pinv(psi_complex) @ (y_complex - omega_complex)  # Shape: (num_samples, d, 1)\n",
    "h_LS_complex = h_LS_complex.squeeze(-1)  # Shape: (num_samples, d)\n",
    "\n",
    "# Split complex numbers into real and imaginary parts\n",
    "h_LS_real = h_LS_complex.real  # Shape: (num_samples, d)\n",
    "h_LS_imag = h_LS_complex.imag  # Shape: (num_samples, d)\n",
    "\n",
    "# Prepare dataset\n",
    "train_dataset = TensorDataset(h_LS_real, h_LS_imag, h_LS_real, h_LS_imag)  # Inputs and outputs for training\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Define candidate operations for the search space\n",
    "OPS = {\n",
    "    'conv_3x3': lambda C: nn.Conv2d(C, C, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "    'conv_5x5': lambda C: nn.Conv2d(C, C, kernel_size=5, stride=1, padding=2, bias=False),\n",
    "    'identity': lambda C: nn.Identity(),\n",
    "    'skip_connection': lambda C: nn.Sequential(nn.Conv2d(C, C, 1, stride=1, bias=False), nn.BatchNorm2d(C)),\n",
    "    'zero': lambda C: nn.ZeroPad2d(0),\n",
    "}\n",
    "\n",
    "# Mixed operation layer with probability-based selection\n",
    "class MixedOp(nn.Module):\n",
    "    def __init__(self, C):\n",
    "        super().__init__()\n",
    "        self.ops = nn.ModuleList([op(C) for op in OPS.values()])\n",
    "        self.alphas = nn.Parameter(torch.randn(len(self.ops)))  # Learnable probabilities\n",
    "    \n",
    "    def forward(self, x):\n",
    "        weights = F.softmax(self.alphas, dim=0)  # Normalize with softmax\n",
    "        return sum(w * op(x) for w, op in zip(weights, self.ops))\n",
    "\n",
    "# Searchable Neural Network with architecture selection\n",
    "class SearchNetwork(nn.Module):\n",
    "    def __init__(self, C, num_layers=3):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([MixedOp(C) for _ in range(num_layers)])\n",
    "        self.output_layer = nn.Conv2d(C, C, kernel_size=1, stride=1, bias=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return self.output_layer(x)\n",
    "\n",
    "# Training function with truncated reverse-mode AD for NAS\n",
    "def train(model, train_loader, arch_optimizer, model_optimizer, criterion, unroll_steps=1):\n",
    "    model.train()\n",
    "    for real_in, imag_in, real_out, imag_out in train_loader:\n",
    "        real_in, imag_in = real_in.unsqueeze(1), imag_in.unsqueeze(1)  # Add channel dimension\n",
    "        real_out, imag_out = real_out.unsqueeze(1), imag_out.unsqueeze(1)\n",
    "        real_in, imag_in, real_out, imag_out = real_in.to(device), imag_in.to(device), real_out.to(device), imag_out.to(device)\n",
    "        \n",
    "        # Compute loss and update model parameters\n",
    "        model_optimizer.zero_grad()\n",
    "        real_pred, imag_pred = model(real_in), model(imag_in)\n",
    "        loss = criterion(real_pred, real_out) + criterion(imag_pred, imag_out)\n",
    "        loss.backward()\n",
    "        model_optimizer.step()\n",
    "        \n",
    "        # Architecture update using truncated differentiation\n",
    "        arch_optimizer.zero_grad()\n",
    "        with torch.no_grad():\n",
    "            temp_model = SearchNetwork(d).to(device)\n",
    "            temp_model.load_state_dict(model.state_dict())\n",
    "        for _ in range(unroll_steps):\n",
    "            real_temp_pred, imag_temp_pred = temp_model(real_in), temp_model(imag_in)\n",
    "            temp_loss = criterion(real_temp_pred, real_out) + criterion(imag_temp_pred, imag_out)\n",
    "            temp_loss.backward()\n",
    "        arch_optimizer.step()\n",
    "\n",
    "# Hyperparameters\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_layers = 3\n",
    "num_epochs = 20\n",
    "\n",
    "# Initialize model and optimizers\n",
    "model = SearchNetwork(d).to(device)\n",
    "arch_optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "model_optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Train model with NAS\n",
    "for epoch in range(num_epochs):\n",
    "    train(model, train_loader, arch_optimizer, model_optimizer, criterion)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} completed.\")\n",
    "\n",
    "# Extract final architecture based on highest probability operations\n",
    "def extract_final_architecture(model):\n",
    "    final_ops = []\n",
    "    for layer in model.layers:\n",
    "        best_op_idx = torch.argmax(layer.alphas).item()\n",
    "        best_op_name = list(OPS.keys())[best_op_idx]\n",
    "        final_ops.append(best_op_name)\n",
    "    return final_ops\n",
    "\n",
    "final_architecture = extract_final_architecture(model)\n",
    "print(\"Final Architecture:\", final_architecture)\n",
    "\n",
    "# Save the best model\n",
    "torch.save(model.state_dict(), \"best_model.pth\")\n",
    "print(\"Neural architecture search completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with the initial 2 convolutional layers that extract features from the input and the decoder module at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Generate synthetic dataset with complex values\n",
    "num_samples = 10000\n",
    "n, d = 150, 512  # Dimensions\n",
    "\n",
    "y_complex = torch.randn(num_samples, n, 1, dtype=torch.cfloat)\n",
    "psi_complex = torch.randn(num_samples, n, d, dtype=torch.cfloat)\n",
    "omega_complex = torch.randn(num_samples, n, 1, dtype=torch.cfloat)\n",
    "\n",
    "# Compute Least Squares Estimate h_LS\n",
    "h_LS_complex = torch.linalg.pinv(psi_complex) @ (y_complex - omega_complex)  # Shape: (num_samples, d, 1)\n",
    "h_LS_complex = h_LS_complex.squeeze(-1)  # Shape: (num_samples, d)\n",
    "\n",
    "# Split into real and imaginary components\n",
    "h_LS_real = h_LS_complex.real  # Shape: (num_samples, d)\n",
    "h_LS_imag = h_LS_complex.imag  # Shape: (num_samples, d)\n",
    "\n",
    "# Prepare dataset\n",
    "train_dataset = TensorDataset(h_LS_real, h_LS_imag, h_LS_real, h_LS_imag)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Feature Extraction Layers\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_type):\n",
    "        super().__init__()\n",
    "        if input_type == 'vector':\n",
    "            self.conv1 = nn.Conv1d(1, 16, kernel_size=3, padding=1)\n",
    "            self.conv2 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "        else:\n",
    "            self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "            self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        return x\n",
    "\n",
    "# NAS Candidate Operations\n",
    "OPS = {\n",
    "    'conv_3x3': lambda C: nn.Conv2d(C, C, kernel_size=3, padding=1, bias=False),\n",
    "    'conv_5x5': lambda C: nn.Conv2d(C, C, kernel_size=5, padding=2, bias=False),\n",
    "    'identity': lambda C: nn.Identity(),\n",
    "    'skip_connection': lambda C: nn.Sequential(nn.Conv2d(C, C, 1, bias=False), nn.BatchNorm2d(C)),\n",
    "    'zero': lambda C: nn.ZeroPad2d(0),\n",
    "}\n",
    "\n",
    "# Mixed Operation Layer\n",
    "class MixedOp(nn.Module):\n",
    "    def __init__(self, C):\n",
    "        super().__init__()\n",
    "        self.ops = nn.ModuleList([op(C) for op in OPS.values()])\n",
    "        self.alphas = nn.Parameter(torch.randn(len(self.ops)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        weights = F.softmax(self.alphas, dim=0)\n",
    "        return sum(w * op(x) for w, op in zip(weights, self.ops))\n",
    "\n",
    "# Searchable Neural Network\n",
    "class SearchNetwork(nn.Module):\n",
    "    def __init__(self, C, num_layers=3):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([MixedOp(C) for _ in range(num_layers)])\n",
    "        self.output_layer = nn.Conv2d(C, C, kernel_size=1, bias=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return self.output_layer(x)\n",
    "\n",
    "# Decoder Module\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_type):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(512, 512)\n",
    "        \n",
    "        if input_type == 'vector':\n",
    "            self.sep_conv1 = nn.Conv1d(32, 16, kernel_size=3, padding=1, groups=16)\n",
    "            self.sep_conv2 = nn.Conv1d(16, 1, kernel_size=3, padding=1, groups=1)\n",
    "            self.final_conv = nn.Conv1d(1, 1, kernel_size=3, padding=1)\n",
    "        else:\n",
    "            self.sep_conv1 = nn.Conv2d(32, 16, kernel_size=3, padding=1, groups=16)\n",
    "            self.sep_conv2 = nn.Conv2d(16, 1, kernel_size=3, padding=1, groups=1)\n",
    "            self.final_conv = nn.Conv2d(1, 1, kernel_size=3, padding=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc(x))\n",
    "        x = F.relu(self.sep_conv1(x))\n",
    "        x = F.relu(self.sep_conv2(x))\n",
    "        return self.final_conv(x)\n",
    "\n",
    "# Complete Model\n",
    "class FullModel(nn.Module):\n",
    "    def __init__(self, input_type):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = FeatureExtractor(input_type)\n",
    "        self.search_network = SearchNetwork(32)\n",
    "        self.decoder = Decoder(input_type)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.search_network(x)\n",
    "        return self.decoder(x)\n",
    "\n",
    "# Training Function\n",
    "def train(model, train_loader, arch_optimizer, model_optimizer, criterion, unroll_steps=1):\n",
    "    model.train()\n",
    "    for real_in, imag_in, real_out, imag_out in train_loader:\n",
    "        real_in, imag_in = real_in.unsqueeze(1), imag_in.unsqueeze(1)  # Add channel dimension\n",
    "        real_out, imag_out = real_out.unsqueeze(1), imag_out.unsqueeze(1)\n",
    "        real_in, imag_in, real_out, imag_out = real_in.to(device), imag_in.to(device), real_out.to(device), imag_out.to(device)\n",
    "        \n",
    "        model_optimizer.zero_grad()\n",
    "        real_pred, imag_pred = model(real_in), model(imag_in)\n",
    "        loss = criterion(real_pred, real_out) + criterion(imag_pred, imag_out)\n",
    "        loss.backward()\n",
    "        model_optimizer.step()\n",
    "        \n",
    "        arch_optimizer.zero_grad()\n",
    "        arch_optimizer.step()\n",
    "\n",
    "# Hyperparameters\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_epochs = 20\n",
    "\n",
    "# Initialize model\n",
    "model = FullModel('vector').to(device)\n",
    "arch_optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "model_optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Train model\n",
    "for epoch in range(num_epochs):\n",
    "    train(model, train_loader, arch_optimizer, model_optimizer, criterion)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} completed.\")\n",
    "\n",
    "torch.save(model.state_dict(), \"best_model.pth\")\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with the DAG denoise cells with 4 nodes in each cell and the sequence of denoise cells have 10 cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Generate synthetic dataset with complex values\n",
    "num_samples = 10000\n",
    "n, d = 150, 512  # Dimensions\n",
    "\n",
    "y_complex = torch.randn(num_samples, n, 1, dtype=torch.cfloat)\n",
    "psi_complex = torch.randn(num_samples, n, d, dtype=torch.cfloat)\n",
    "omega_complex = torch.randn(num_samples, n, 1, dtype=torch.cfloat)\n",
    "\n",
    "# Compute Least Squares Estimate h_LS\n",
    "h_LS_complex = torch.linalg.pinv(psi_complex) @ (y_complex - omega_complex)\n",
    "h_LS_complex = h_LS_complex.squeeze(-1)\n",
    "\n",
    "# Split into real and imaginary components\n",
    "h_LS_real = h_LS_complex.real\n",
    "h_LS_imag = h_LS_complex.imag\n",
    "\n",
    "# Prepare dataset\n",
    "train_dataset = TensorDataset(h_LS_real, h_LS_imag, h_LS_real, h_LS_imag)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Feature Extraction Layers\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        return x\n",
    "\n",
    "# NAS Candidate Operations\n",
    "OPS = {\n",
    "    'conv_3x3': lambda C: nn.Conv1d(C, C, kernel_size=3, padding=1, bias=False),\n",
    "    'conv_5x5': lambda C: nn.Conv1d(C, C, kernel_size=5, padding=2, bias=False),\n",
    "    'identity': lambda C: nn.Identity(),\n",
    "    'skip_connection': lambda C: nn.Sequential(nn.Conv1d(C, C, 1, bias=False), nn.BatchNorm1d(C)),\n",
    "    'zero': lambda C: nn.ZeroPad1d(0),\n",
    "}\n",
    "\n",
    "# Denoise Cell\n",
    "class DenoiseCell(nn.Module):\n",
    "    def __init__(self, C):\n",
    "        super().__init__()\n",
    "        self.ops = nn.ModuleList([op(C) for op in OPS.values()])\n",
    "        self.alphas = nn.Parameter(torch.randn(len(self.ops), 3))  # 3 edges per cell\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        assert len(inputs) == 2, \"Each denoise cell must take two inputs.\"\n",
    "        node_outputs = [inputs[0], inputs[1], torch.zeros_like(inputs[0]), torch.zeros_like(inputs[0])]\n",
    "        \n",
    "        for i in range(3):  # Three edges per cell\n",
    "            weights = F.softmax(self.alphas[:, i], dim=0)\n",
    "            node_outputs[i + 1] = sum(w * op(node_outputs[i]) for w, op in zip(weights, self.ops))\n",
    "        \n",
    "        return node_outputs[-1]\n",
    "\n",
    "# Sequence of 10 Denoise Cells\n",
    "class DenoiseModule(nn.Module):\n",
    "    def __init__(self, C):\n",
    "        super().__init__()\n",
    "        self.cells = nn.ModuleList([DenoiseCell(C) for _ in range(10)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1, out2 = x, x  # First two cells take same input\n",
    "        outputs = [out1, out2]\n",
    "        \n",
    "        for i in range(10):\n",
    "            out = self.cells[i]([outputs[-2], outputs[-1]])\n",
    "            outputs.append(out)\n",
    "        \n",
    "        return outputs[-1]\n",
    "\n",
    "# Decoder Module\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(512, 512)\n",
    "        self.sep_conv1 = nn.Conv1d(32, 16, kernel_size=3, padding=1, groups=16)\n",
    "        self.sep_conv2 = nn.Conv1d(16, 1, kernel_size=3, padding=1, groups=1)\n",
    "        self.final_conv = nn.Conv1d(1, 1, kernel_size=3, padding=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc(x))\n",
    "        x = F.relu(self.sep_conv1(x))\n",
    "        x = F.relu(self.sep_conv2(x))\n",
    "        return self.final_conv(x)\n",
    "\n",
    "# Complete Model\n",
    "class FullModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = FeatureExtractor()\n",
    "        self.denoise_module = DenoiseModule(32)\n",
    "        self.decoder = Decoder()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.denoise_module(x)\n",
    "        return self.decoder(x)\n",
    "\n",
    "# Training Function\n",
    "def train(model, train_loader, arch_optimizer, model_optimizer, criterion):\n",
    "    model.train()\n",
    "    for real_in, imag_in, real_out, imag_out in train_loader:\n",
    "        real_in, imag_in = real_in.unsqueeze(1), imag_in.unsqueeze(1)  # Add channel dimension\n",
    "        real_out, imag_out = real_out.unsqueeze(1), imag_out.unsqueeze(1)\n",
    "        real_in, imag_in, real_out, imag_out = real_in.to(device), imag_in.to(device), real_out.to(device), imag_out.to(device)\n",
    "        \n",
    "        model_optimizer.zero_grad()\n",
    "        real_pred, imag_pred = model(real_in), model(imag_in)\n",
    "        loss = criterion(real_pred, real_out) + criterion(imag_pred, imag_out)\n",
    "        loss.backward()\n",
    "        model_optimizer.step()\n",
    "        \n",
    "        arch_optimizer.zero_grad()\n",
    "        arch_optimizer.step()\n",
    "\n",
    "# Hyperparameters\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_epochs = 20\n",
    "\n",
    "# Initialize model\n",
    "model = FullModel().to(device)\n",
    "arch_optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "model_optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Train model\n",
    "for epoch in range(num_epochs):\n",
    "    train(model, train_loader, arch_optimizer, model_optimizer, criterion)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} completed.\")\n",
    "\n",
    "torch.save(model.state_dict(), \"best_model.pth\")\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with 6 edges in each denoise cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Generate synthetic dataset with complex values\n",
    "num_samples = 10000\n",
    "n, d = 150, 512  # Dimensions\n",
    "\n",
    "y_complex = torch.randn(num_samples, n, 1, dtype=torch.cfloat)\n",
    "psi_complex = torch.randn(num_samples, n, d, dtype=torch.cfloat)\n",
    "omega_complex = torch.randn(num_samples, n, 1, dtype=torch.cfloat)\n",
    "\n",
    "# Compute Least Squares Estimate h_LS\n",
    "h_LS_complex = torch.linalg.pinv(psi_complex) @ (y_complex - omega_complex)\n",
    "h_LS_complex = h_LS_complex.squeeze(-1)\n",
    "\n",
    "# Split into real and imaginary components\n",
    "h_LS_real = h_LS_complex.real\n",
    "h_LS_imag = h_LS_complex.imag\n",
    "\n",
    "# Prepare dataset\n",
    "train_dataset = TensorDataset(h_LS_real, h_LS_imag, h_LS_real, h_LS_imag)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Feature Extraction Layers\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        return x\n",
    "\n",
    "# NAS Candidate Operations\n",
    "OPS = {\n",
    "    'conv_3x3': lambda C: nn.Conv1d(C, C, kernel_size=3, padding=1, bias=False),\n",
    "    'conv_5x5': lambda C: nn.Conv1d(C, C, kernel_size=5, padding=2, bias=False),\n",
    "    'identity': lambda C: nn.Identity(),\n",
    "    'skip_connection': lambda C: nn.Sequential(nn.Conv1d(C, C, 1, bias=False), nn.BatchNorm1d(C)),\n",
    "    'zero': lambda C: nn.ZeroPad1d(0),\n",
    "}\n",
    "\n",
    "# Denoise Cell with DAG Structure\n",
    "class DenoiseCell(nn.Module):\n",
    "    def __init__(self, C):\n",
    "        super().__init__()\n",
    "        self.ops = nn.ModuleList([op(C) for op in OPS.values()])\n",
    "        self.alphas = nn.Parameter(torch.randn(len(self.ops), 6))  # 6 edges in DAG\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        assert len(inputs) == 2, \"Each denoise cell must take two inputs.\"\n",
    "        node_outputs = [inputs[0], inputs[1], torch.zeros_like(inputs[0]), torch.zeros_like(inputs[0])]\n",
    "        \n",
    "        edges = [(0, 2), (0, 3), (0, 4), (2, 3), (2, 4), (3, 4)]\n",
    "        for edge_idx, (src, dest) in enumerate(edges):\n",
    "            weights = F.softmax(self.alphas[:, edge_idx], dim=0)\n",
    "            node_outputs[dest] += sum(w * op(node_outputs[src]) for w, op in zip(weights, self.ops))\n",
    "        \n",
    "        return node_outputs[4]  # Output of last node\n",
    "\n",
    "# Sequence of 10 Denoise Cells\n",
    "class DenoiseModule(nn.Module):\n",
    "    def __init__(self, C):\n",
    "        super().__init__()\n",
    "        self.cells = nn.ModuleList([DenoiseCell(C) for _ in range(10)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1, out2 = x, x\n",
    "        outputs = [out1, out2]\n",
    "        \n",
    "        for i in range(10):\n",
    "            out = self.cells[i]([outputs[-2], outputs[-1]])\n",
    "            outputs.append(out)\n",
    "        \n",
    "        return outputs[-1]\n",
    "\n",
    "# Decoder Module\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(512, 512)\n",
    "        self.sep_conv1 = nn.Conv1d(32, 16, kernel_size=3, padding=1, groups=16)\n",
    "        self.sep_conv2 = nn.Conv1d(16, 1, kernel_size=3, padding=1, groups=1)\n",
    "        self.final_conv = nn.Conv1d(1, 1, kernel_size=3, padding=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc(x))\n",
    "        x = F.relu(self.sep_conv1(x))\n",
    "        x = F.relu(self.sep_conv2(x))\n",
    "        return self.final_conv(x)\n",
    "\n",
    "# Complete Model\n",
    "class FullModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = FeatureExtractor()\n",
    "        self.denoise_module = DenoiseModule(32)\n",
    "        self.decoder = Decoder()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.denoise_module(x)\n",
    "        return self.decoder(x)\n",
    "\n",
    "# Training Function\n",
    "def train(model, train_loader, arch_optimizer, model_optimizer, criterion):\n",
    "    model.train()\n",
    "    for real_in, imag_in, real_out, imag_out in train_loader:\n",
    "        real_in, imag_in = real_in.unsqueeze(1), imag_in.unsqueeze(1)\n",
    "        real_out, imag_out = real_out.unsqueeze(1), imag_out.unsqueeze(1)\n",
    "        real_in, imag_in, real_out, imag_out = real_in.to(device), imag_in.to(device), real_out.to(device), imag_out.to(device)\n",
    "        \n",
    "        model_optimizer.zero_grad()\n",
    "        real_pred, imag_pred = model(real_in), model(imag_in)\n",
    "        loss = criterion(real_pred, real_out) + criterion(imag_pred, imag_out)\n",
    "        loss.backward()\n",
    "        model_optimizer.step()\n",
    "        \n",
    "        arch_optimizer.zero_grad()\n",
    "        arch_optimizer.step()\n",
    "\n",
    "# Hyperparameters\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_epochs = 20\n",
    "\n",
    "# Initialize model\n",
    "model = FullModel().to(device)\n",
    "arch_optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "model_optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Train model\n",
    "for epoch in range(num_epochs):\n",
    "    train(model, train_loader, arch_optimizer, model_optimizer, criterion)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} completed.\")\n",
    "\n",
    "torch.save(model.state_dict(), \"best_model.pth\")\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with base 2 denoise cells sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Generate synthetic dataset with complex values\n",
    "num_samples = 10000\n",
    "n, d = 150, 512  # Dimensions\n",
    "\n",
    "y_complex = torch.randn(num_samples, n, 1, dtype=torch.cfloat)\n",
    "psi_complex = torch.randn(num_samples, n, d, dtype=torch.cfloat)\n",
    "omega_complex = torch.randn(num_samples, n, 1, dtype=torch.cfloat)\n",
    "\n",
    "# Compute Least Squares Estimate h_LS\n",
    "h_LS_complex = torch.linalg.pinv(psi_complex) @ (y_complex - omega_complex)\n",
    "h_LS_complex = h_LS_complex.squeeze(-1)\n",
    "\n",
    "# Split into real and imaginary components\n",
    "h_LS_real = h_LS_complex.real\n",
    "h_LS_imag = h_LS_complex.imag\n",
    "\n",
    "# Prepare dataset\n",
    "train_dataset = TensorDataset(h_LS_real, h_LS_imag, h_LS_real, h_LS_imag)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Feature Extraction Layers\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        return x\n",
    "\n",
    "# NAS Candidate Operations\n",
    "OPS = {\n",
    "    'conv_3x3': lambda C: nn.Conv1d(C, C, kernel_size=3, padding=1, bias=False),\n",
    "    'conv_5x5': lambda C: nn.Conv1d(C, C, kernel_size=5, padding=2, bias=False),\n",
    "    'identity': lambda C: nn.Identity(),\n",
    "    'skip_connection': lambda C: nn.Sequential(nn.Conv1d(C, C, 1, bias=False), nn.BatchNorm1d(C)),\n",
    "    'zero': lambda C: nn.ZeroPad1d(0),\n",
    "}\n",
    "\n",
    "# Denoise Cell with DAG Structure\n",
    "class DenoiseCell(nn.Module):\n",
    "    def __init__(self, C):\n",
    "        super().__init__()\n",
    "        self.ops = nn.ModuleList([op(C) for op in OPS.values()])\n",
    "        self.alphas = nn.Parameter(torch.randn(len(self.ops), 6))  # 6 edges in DAG\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        assert len(inputs) == 2, \"Each denoise cell must take two inputs.\"\n",
    "        node_outputs = [inputs[0], inputs[1], torch.zeros_like(inputs[0]), torch.zeros_like(inputs[0])]\n",
    "        \n",
    "        edges = [(0, 2), (0, 3), (0, 4), (2, 3), (2, 4), (3, 4)]\n",
    "        for edge_idx, (src, dest) in enumerate(edges):\n",
    "            weights = F.softmax(self.alphas[:, edge_idx], dim=0)\n",
    "            node_outputs[dest] += sum(w * op(node_outputs[src]) for w, op in zip(weights, self.ops))\n",
    "        \n",
    "        return node_outputs[4]  # Output of last node\n",
    "\n",
    "# Sequence of 10 Denoise Cells\n",
    "class DenoiseModule(nn.Module):\n",
    "    def __init__(self, C):\n",
    "        super().__init__()\n",
    "        self.cells = nn.ModuleList([DenoiseCell(C) for _ in range(10)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1, out2 = x, x  # Initial input duplicated for first denoise cell\n",
    "        outputs = [out1, out2]\n",
    "        \n",
    "        for i in range(10):\n",
    "            if i == 0:\n",
    "                # First cell: use feature extraction output twice\n",
    "                out = self.cells[i]([out1, out1])\n",
    "            elif i == 1:\n",
    "                # Second cell: use output of first cell and original feature extraction output\n",
    "                out = self.cells[i]([outputs[1], out1])\n",
    "            else:\n",
    "                # Remaining cells: use last 2 outputs\n",
    "                out = self.cells[i]([outputs[-2], outputs[-1]])\n",
    "            \n",
    "            outputs.append(out)\n",
    "        \n",
    "        return outputs[-1]\n",
    "\n",
    "# Decoder Module\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(512, 512)\n",
    "        self.sep_conv1 = nn.Conv1d(32, 16, kernel_size=3, padding=1, groups=16)\n",
    "        self.sep_conv2 = nn.Conv1d(16, 1, kernel_size=3, padding=1, groups=1)\n",
    "        self.final_conv = nn.Conv1d(1, 1, kernel_size=3, padding=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc(x))\n",
    "        x = F.relu(self.sep_conv1(x))\n",
    "        x = F.relu(self.sep_conv2(x))\n",
    "        return self.final_conv(x)\n",
    "\n",
    "# Complete Model\n",
    "class FullModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = FeatureExtractor()\n",
    "        self.denoise_module = DenoiseModule(32)\n",
    "        self.decoder = Decoder()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.denoise_module(x)\n",
    "        return self.decoder(x)\n",
    "\n",
    "# Training Function\n",
    "def train(model, train_loader, arch_optimizer, model_optimizer, criterion):\n",
    "    model.train()\n",
    "    for real_in, imag_in, real_out, imag_out in train_loader:\n",
    "        real_in, imag_in = real_in.unsqueeze(1), imag_in.unsqueeze(1)\n",
    "        real_out, imag_out = real_out.unsqueeze(1), imag_out.unsqueeze(1)\n",
    "        real_in, imag_in, real_out, imag_out = real_in.to(device), imag_in.to(device), real_out.to(device), imag_out.to(device)\n",
    "        \n",
    "        model_optimizer.zero_grad()\n",
    "        real_pred, imag_pred = model(real_in), model(imag_in)\n",
    "        loss = criterion(real_pred, real_out) + criterion(imag_pred, imag_out)\n",
    "        loss.backward()\n",
    "        model_optimizer.step()\n",
    "        \n",
    "        arch_optimizer.zero_grad()\n",
    "        arch_optimizer.step()\n",
    "\n",
    "# Hyperparameters\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_epochs = 20\n",
    "\n",
    "# Initialize model\n",
    "model = FullModel().to(device)\n",
    "arch_optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "model_optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Train model\n",
    "for epoch in range(num_epochs):\n",
    "    train(model, train_loader, arch_optimizer, model_optimizer, criterion)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} completed.\")\n",
    "\n",
    "torch.save(model.state_dict(), \"best_model.pth\")\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with aggrehgation done in cases where there at mutiple inputs in the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Generate synthetic dataset with complex values\n",
    "num_samples = 10000\n",
    "n, d = 150, 512  # Dimensions\n",
    "\n",
    "y_complex = torch.randn(num_samples, n, 1, dtype=torch.cfloat)\n",
    "psi_complex = torch.randn(num_samples, n, d, dtype=torch.cfloat)\n",
    "omega_complex = torch.randn(num_samples, n, 1, dtype=torch.cfloat)\n",
    "\n",
    "# Compute Least Squares Estimate h_LS\n",
    "h_LS_complex = torch.linalg.pinv(psi_complex) @ (y_complex - omega_complex)\n",
    "h_LS_complex = h_LS_complex.squeeze(-1)\n",
    "\n",
    "# Split into real and imaginary components\n",
    "h_LS_real = h_LS_complex.real\n",
    "h_LS_imag = h_LS_complex.imag\n",
    "\n",
    "# Prepare dataset\n",
    "train_dataset = TensorDataset(h_LS_real, h_LS_imag, h_LS_real, h_LS_imag)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Feature Extraction Layers\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        return x\n",
    "\n",
    "# NAS Candidate Operations\n",
    "OPS = {\n",
    "    'conv_3x3': lambda C: nn.Conv1d(C, C, kernel_size=3, padding=1, bias=False),\n",
    "    'conv_5x5': lambda C: nn.Conv1d(C, C, kernel_size=5, padding=2, bias=False),\n",
    "    'identity': lambda C: nn.Identity(),\n",
    "    'skip_connection': lambda C: nn.Sequential(nn.Conv1d(C, C, 1, bias=False), nn.BatchNorm1d(C)),\n",
    "    'zero': lambda C: nn.ZeroPad1d(0),\n",
    "}\n",
    "\n",
    "# Denoise Cell with DAG Structure\n",
    "class DenoiseCell(nn.Module):\n",
    "    def __init__(self, C):\n",
    "        super().__init__()\n",
    "        self.C = C\n",
    "        self.ops = nn.ModuleList([op(C) for op in OPS.values()])\n",
    "        self.alphas = nn.Parameter(torch.randn(len(self.ops), 6))  # 6 edges in DAG\n",
    "\n",
    "        # 1x1 convolution to reduce dimensions after concatenation for node 3\n",
    "        self.conv1x1_node3 = nn.Conv1d(3 * C, C, kernel_size=1, bias=False)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        assert len(inputs) == 2, \"Each denoise cell must take two inputs.\"\n",
    "        # Concatenation for nodes 0 and 2\n",
    "        node0 = torch.cat(inputs, dim=1)\n",
    "        node2 = torch.cat(inputs, dim=1)\n",
    "        \n",
    "        node_outputs = [\n",
    "            F.relu(node0),  # Node 0: concatenation of 2 inputs\n",
    "            F.relu(node2),  # Node 1: concatenation of 2 inputs\n",
    "            torch.zeros_like(inputs[0]),  # Node 2\n",
    "            torch.zeros_like(inputs[0]),  # Node 3\n",
    "            torch.zeros_like(inputs[0]),  # Node 4\n",
    "        ]\n",
    "        \n",
    "        edges = [(0, 2), (0, 3), (0, 4), (2, 3), (2, 4), (3, 4)]\n",
    "        for edge_idx, (src, dest) in enumerate(edges):\n",
    "            weights = F.softmax(self.alphas[:, edge_idx], dim=0)\n",
    "            aggregated_output = sum(w * op(node_outputs[src]) for w, op in zip(weights, self.ops))\n",
    "\n",
    "            if dest == 3:\n",
    "                # Node 3: Concatenate 3 inputs and reduce dimensions with 1x1 convolution\n",
    "                node_outputs[dest] = F.relu(self.conv1x1_node3(torch.cat([node_outputs[0], node_outputs[1], aggregated_output], dim=1)))\n",
    "            elif dest == 2:\n",
    "                node_outputs[dest] += aggregated_output\n",
    "            else:\n",
    "                node_outputs[dest] += aggregated_output\n",
    "        \n",
    "        return node_outputs[4]  # Output of last node\n",
    "\n",
    "# Sequence of 10 Denoise Cells\n",
    "class DenoiseModule(nn.Module):\n",
    "    def __init__(self, C):\n",
    "        super().__init__()\n",
    "        self.cells = nn.ModuleList([DenoiseCell(C) for _ in range(10)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1, out2 = x, x  # Initial input duplicated for first denoise cell\n",
    "        outputs = [out1, out2]\n",
    "        \n",
    "        for i in range(10):\n",
    "            if i == 0:\n",
    "                # First cell: use feature extraction output twice\n",
    "                out = self.cells[i]([out1, out1])\n",
    "            elif i == 1:\n",
    "                # Second cell: use output of first cell and original feature extraction output\n",
    "                out = self.cells[i]([outputs[1], out1])\n",
    "            else:\n",
    "                # Remaining cells: use last 2 outputs\n",
    "                out = self.cells[i]([outputs[-2], outputs[-1]])\n",
    "            \n",
    "            outputs.append(out)\n",
    "        \n",
    "        return outputs[-1]\n",
    "\n",
    "# Decoder Module\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(512, 512)\n",
    "        self.sep_conv1 = nn.Conv1d(32, 16, kernel_size=3, padding=1, groups=16)\n",
    "        self.sep_conv2 = nn.Conv1d(16, 1, kernel_size=3, padding=1, groups=1)\n",
    "        self.final_conv = nn.Conv1d(1, 1, kernel_size=3, padding=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc(x))\n",
    "        x = F.relu(self.sep_conv1(x))\n",
    "        x = F.relu(self.sep_conv2(x))\n",
    "        return self.final_conv(x)\n",
    "\n",
    "# Complete Model\n",
    "class FullModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = FeatureExtractor()\n",
    "        self.denoise_module = DenoiseModule(32)\n",
    "        self.decoder = Decoder()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.denoise_module(x)\n",
    "        return self.decoder(x)\n",
    "\n",
    "# Training Function\n",
    "def train(model, train_loader, arch_optimizer, model_optimizer, criterion):\n",
    "    model.train()\n",
    "    for real_in, imag_in, real_out, imag_out in train_loader:\n",
    "        real_in, imag_in = real_in.unsqueeze(1), imag_in.unsqueeze(1)\n",
    "        real_out, imag_out = real_out.unsqueeze(1), imag_out.unsqueeze(1)\n",
    "        real_in, imag_in, real_out, imag_out = real_in.to(device), imag_out.to(device), real_out.to(device), imag_out.to(device)\n",
    "        \n",
    "        model_optimizer.zero_grad()\n",
    "        real_pred, imag_pred = model(real_in), model(imag_in)\n",
    "        loss = criterion(real_pred, real_out) + criterion(imag_pred, imag_out)\n",
    "        loss.backward()\n",
    "        model_optimizer.step()\n",
    "        \n",
    "        arch_optimizer.zero_grad()\n",
    "        arch_optimizer.step()\n",
    "\n",
    "# Hyperparameters\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_epochs = 20\n",
    "\n",
    "# Initialize model\n",
    "model = FullModel().to(device)\n",
    "arch_optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "model_optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Train model\n",
    "for epoch in range(num_epochs):\n",
    "    train(model, train_loader, arch_optimizer, model_optimizer, criterion)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} completed.\")\n",
    "\n",
    "torch.save(model.state_dict(), \"best_model.pth\")\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Generate synthetic dataset with complex values\n",
    "num_samples = 10000\n",
    "n, d = 150, 512  # Dimensions\n",
    "\n",
    "y_complex = torch.randn(num_samples, n, 1, dtype=torch.cfloat)\n",
    "psi_complex = torch.randn(num_samples, n, d, dtype=torch.cfloat)\n",
    "omega_complex = torch.randn(num_samples, n, 1, dtype=torch.cfloat)\n",
    "\n",
    "# Compute Least Squares Estimate h_LS\n",
    "h_LS_complex = torch.linalg.pinv(psi_complex) @ (y_complex - omega_complex)\n",
    "h_LS_complex = h_LS_complex.squeeze(-1)\n",
    "\n",
    "# Split into real and imaginary components\n",
    "h_LS_real = h_LS_complex.real\n",
    "h_LS_imag = h_LS_complex.imag\n",
    "\n",
    "# Prepare dataset\n",
    "train_dataset = TensorDataset(h_LS_real, h_LS_imag, h_LS_real, h_LS_imag)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Feature Extraction Layers\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        return x\n",
    "\n",
    "# NAS Candidate Operations\n",
    "OPS = {\n",
    "    'conv_3x3': lambda C: nn.Conv1d(C, C, kernel_size=3, padding=1, bias=False),\n",
    "    'conv_5x5': lambda C: nn.Conv1d(C, C, kernel_size=5, padding=2, bias=False),\n",
    "    'identity': lambda C: nn.Identity(),\n",
    "    'skip_connection': lambda C: nn.Sequential(nn.Conv1d(C, C, 1, bias=False), nn.BatchNorm1d(C)),\n",
    "    'zero': lambda C: nn.ZeroPad1d(0),\n",
    "}\n",
    "\n",
    "# Denoise Cell with DAG Structure\n",
    "class DenoiseCell(nn.Module):\n",
    "    def _init_(self, C):\n",
    "        super()._init_()\n",
    "        self.C = C\n",
    "        self.ops = nn.ModuleList([op(C) for op in OPS.values()])\n",
    "        self.alphas = nn.Parameter(torch.randn(len(self.ops), 6))  # 6 edges in DAG\n",
    "\n",
    "        # 1x1 convolution to reduce dimensions after concatenation for node 3\n",
    "        self.conv1x1_node3 = nn.Conv1d(3 * C, C, kernel_size=1, bias=False)\n",
    "\n",
    "    def pad_and_concat(self, inputs):\n",
    "        \"\"\"Finds the max size, zero-pads smaller inputs, and concatenates along the channel dimension.\"\"\"\n",
    "        max_size = max(inp.shape[2] for inp in inputs)  # Find the largest temporal dimension\n",
    "        padded_inputs = [\n",
    "            F.pad(inp, (0, max_size - inp.shape[2])) if inp.shape[2] < max_size else inp\n",
    "            for inp in inputs\n",
    "        ]\n",
    "        return torch.cat(padded_inputs, dim=1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        assert len(inputs) == 2, \"Each denoise cell must take two inputs.\"\n",
    "        \n",
    "        node_outputs = [None] * 4  # Initialize all nodes\n",
    "        \n",
    "        # Node 0: Receives both inputs, pads them, and concatenates\n",
    "        node_outputs[0] = F.relu(self.pad_and_concat(inputs))\n",
    "        \n",
    "        # Node 1: Receives only node 0's output\n",
    "        node_outputs[1] = F.relu(node_outputs[0])\n",
    "        \n",
    "        # Node 2: Receives input from node 0 and node 1 (must pad and concat)\n",
    "        node_outputs[2] = F.relu(self.pad_and_concat([node_outputs[0], node_outputs[1]]))\n",
    "        \n",
    "        # Node 3: Receives inputs from nodes 0, 1, and 2 (pad and concat)\n",
    "        padded_inputs_node3 = self.pad_and_concat([node_outputs[0], node_outputs[1], node_outputs[2]])\n",
    "        node_outputs[3] = F.relu(self.conv1x1_node3(padded_inputs_node3))\n",
    "        \n",
    "        return node_outputs[3]  # Output of node 3\n",
    "\n",
    "# Sequence of 10 Denoise Cells\n",
    "class DenoiseModule(nn.Module):\n",
    "    def __init__(self, C):\n",
    "        super().__init__()\n",
    "        self.cells = nn.ModuleList([DenoiseCell(C) for _ in range(10)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1, out2 = x, x  # Initial input duplicated for first denoise cell\n",
    "        outputs = [out1, out2]\n",
    "        \n",
    "        for i in range(10):\n",
    "            if i == 0:\n",
    "                # First cell: use feature extraction output twice\n",
    "                out = self.cells[i]([out1, out1])\n",
    "            elif i == 1:\n",
    "                # Second cell: use output of first cell and original feature extraction output\n",
    "                out = self.cells[i]([outputs[1], out1])\n",
    "            else:\n",
    "                # Remaining cells: use last 2 outputs\n",
    "                out = self.cells[i]([outputs[-2], outputs[-1]])\n",
    "            \n",
    "            outputs.append(out)\n",
    "        \n",
    "        return outputs[-1]\n",
    "\n",
    "# Decoder Module\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(512, 512)\n",
    "        self.sep_conv1 = nn.Conv1d(32, 16, kernel_size=3, padding=1, groups=16)\n",
    "        self.sep_conv2 = nn.Conv1d(16, 1, kernel_size=3, padding=1, groups=1)\n",
    "        self.final_conv = nn.Conv1d(1, 1, kernel_size=3, padding=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc(x))\n",
    "        x = F.relu(self.sep_conv1(x))\n",
    "        x = F.relu(self.sep_conv2(x))\n",
    "        return self.final_conv(x)\n",
    "\n",
    "# Complete Model\n",
    "class FullModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = FeatureExtractor()\n",
    "        self.denoise_module = DenoiseModule(32)\n",
    "        self.decoder = Decoder()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.denoise_module(x)\n",
    "        return self.decoder(x)\n",
    "\n",
    "# Training Function\n",
    "def train(model, train_loader, arch_optimizer, model_optimizer, criterion):\n",
    "    model.train()\n",
    "    for real_in, imag_in, real_out, imag_out in train_loader:\n",
    "        real_in, imag_in = real_in.unsqueeze(1), imag_in.unsqueeze(1)\n",
    "        real_out, imag_out = real_out.unsqueeze(1), imag_out.unsqueeze(1)\n",
    "        real_in, imag_in, real_out, imag_out = real_in.to(device), imag_out.to(device), real_out.to(device), imag_out.to(device)\n",
    "        \n",
    "        model_optimizer.zero_grad()\n",
    "        real_pred, imag_pred = model(real_in), model(imag_in)\n",
    "        loss = criterion(real_pred, real_out) + criterion(imag_pred, imag_out)\n",
    "        loss.backward()\n",
    "        model_optimizer.step()\n",
    "        \n",
    "        arch_optimizer.zero_grad()\n",
    "        arch_optimizer.step()\n",
    "\n",
    "# Hyperparameters\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_epochs = 20\n",
    "\n",
    "# Initialize model\n",
    "model = FullModel().to(device)\n",
    "arch_optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "model_optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Train model\n",
    "for epoch in range(num_epochs):\n",
    "    train(model, train_loader, arch_optimizer, model_optimizer, criterion)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} completed.\")\n",
    "\n",
    "torch.save(model.state_dict(), \"best_model.pth\")\n",
    "print(\"Training completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "irsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
